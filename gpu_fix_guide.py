#!/usr/bin/env python3
"""
Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø±ÙØ¹ Ù…Ø³Ø¦Ù„Ù‡ GPU Utilization
======================================

Ù…Ø³Ø¦Ù„Ù‡ Ø´Ù…Ø§: GPU utilization Ø¨ÛŒÙ† 40% Ùˆ 2% Ù†ÙˆØ³Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯
Ø¹Ù„Øª: Data loading inefficiency Ùˆ CPU-GPU synchronization Ù…Ø´Ú©Ù„Ø§Øª

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:
1. GPU Utilization Optimizer
2. Async Data Prefetching  
3. Optimized DataLoader
4. Real-time Monitoring
5. Memory Management

"""

import subprocess
import time
import sys
from pathlib import Path

def check_requirements():
    """Ø¨Ø±Ø±Ø³ÛŒ requirements Ù„Ø§Ø²Ù…"""
    print("ğŸ” Checking requirements...")
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
            print(f"âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    except ImportError:
        print("âŒ PyTorch not found")
        return False
    
    try:
        import pynvml
        print("âœ… pynvml available for GPU monitoring")
    except ImportError:
        print("âš ï¸  pynvml not found, installing...")
        subprocess.run([sys.executable, "-m", "pip", "install", "nvidia-ml-py"], check=True)
    
    try:
        import psutil
        print("âœ… psutil available")
    except ImportError:
        print("âš ï¸  psutil not found, installing...")
        subprocess.run([sys.executable, "-m", "pip", "install", "psutil"], check=True)
    
    return True

def show_gpu_optimization_guide():
    """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ GPU"""
    print("""
ğŸ¯ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø±ÙØ¹ Ù…Ø³Ø¦Ù„Ù‡ GPU Utilization
=====================================

Ù…Ø³Ø¦Ù„Ù‡ Ø´Ù…Ø§:
- GPU utilization Ø¨ÛŒÙ† 40% Ùˆ 2% Ù†ÙˆØ³Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§Ù„ training Ø§Ø³Øª ÙˆÙ„ÛŒ GPU Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
- Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÛŒÚ©Ù‡ ØªÛŒÚ©Ù‡ ÙˆØ§Ø±Ø¯ GPU Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯

Ø¹Ù„Ù„ Ø§ØµÙ„ÛŒ:
1. Data loading bottleneck (CPU Ú©Ù†Ø¯ Ø§Ø³Øª)
2. Synchronous data transfer (CPU Ù…Ù†ØªØ¸Ø± GPU Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯)
3. Insufficient prefetching (Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ù†ÛŒØ³ØªÙ†Ø¯)
4. Memory management Ù†Ø§Ú©Ø§Ø±Ø¢Ù…Ø¯
5. Worker thread Ù‡Ø§ÛŒ Ú©Ù…

Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:
==========================

1. ğŸš€ GPU Utilization Optimizer:
   - Async data prefetching
   - Multi-threaded data loading
   - GPU memory pool management
   - Real-time monitoring

2. ğŸ“Š DataLoader Optimizations:
   - Increased num_workers (8-16)
   - Higher prefetch_factor (4-8)
   - Persistent workers
   - Pin memory enabled
   - Drop last batch for consistency

3. ğŸ§  Memory Management:
   - Optimized memory fraction
   - Gradient checkpointing
   - Memory cleanup intervals
   - Async GPU transfers

4. ğŸ“ˆ Real-time Monitoring:
   - GPU utilization tracking
   - Memory usage monitoring
   - Performance recommendations
   - Automatic optimization

Ø§Ø³ØªÙØ§Ø¯Ù‡:
========

Ø±ÙˆØ´ 1 - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¢Ù…Ø§Ø¯Ù‡:
./train_gpu_optimized.sh

Ø±ÙˆØ´ 2 - Ø¯Ø³ØªÛŒ:
python3 train_main.py --config config_gpu_utilization_optimized.yaml --model-size tiny

Ø±ÙˆØ´ 3 - Ø¨Ø§ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ú©Ø§Ù…Ù„:
python3 train_main.py --model-size tiny --optimization-level enhanced --apply-fast-convergence

Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:
==================
- GPU utilization: 80-95% (stable)
- Memory usage: 70-85%
- Training speed: 2-3x Ø¨Ù‡ØªØ±
- Ú©Ø§Ù‡Ø´ data loading latency
- Stable performance Ø¨Ø¯ÙˆÙ† Ù†ÙˆØ³Ø§Ù†

""")

def run_gpu_benchmark():
    """Ø§Ø¬Ø±Ø§ÛŒ benchmark GPU utilization"""
    print("ğŸ§ª Running GPU utilization benchmark...")
    
    try:
        from gpu_utilization_optimizer import create_gpu_optimizer
        import torch
        
        if not torch.cuda.is_available():
            print("âŒ CUDA not available")
            return
        
        device = torch.device('cuda')
        optimizer = create_gpu_optimizer(device)
        
        print("ğŸ“Š Monitoring GPU for 30 seconds...")
        
        for i in range(30):
            stats = optimizer.monitor_gpu_utilization()
            if stats:
                gpu_util = stats.get('gpu_utilization', 0)
                memory_util = stats.get('memory_used_percent', 0)
                print(f"Step {i+1:2d}: GPU={gpu_util:3.0f}%, Memory={memory_util:5.1f}%")
            
            time.sleep(1)
        
        recommendations = optimizer.get_optimization_recommendations()
        if recommendations.get('recommendations'):
            print("\nğŸ’¡ Recommendations:")
            for rec in recommendations['recommendations']:
                print(f"   - {rec['issue']}: {rec['solution']}")
        
        optimizer.stop_optimization()
        
    except Exception as e:
        print(f"âŒ Benchmark failed: {e}")

def test_optimized_training():
    """ØªØ³Øª training Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡"""
    print("\nğŸ¯ Testing optimized training setup...")
    
    config_file = "config_gpu_utilization_optimized.yaml"
    if not Path(config_file).exists():
        print(f"âŒ Config file not found: {config_file}")
        print("Run: python3 gpu_utilization_config.py")
        return
    
    print(f"âœ… Config file found: {config_file}")
    
    # Test with dry run
    cmd = [
        "python3", "train_main.py",
        "--config", config_file,
        "--model-size", "tiny",
        "--epochs", "1",  # Just one epoch for testing
        "--optimization-level", "enhanced"
    ]
    
    print(f"Test command: {' '.join(cmd)}")
    print("This would start optimized training with GPU utilization monitoring.")
    print("The actual training will show real-time GPU stats and recommendations.")

def main():
    """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ"""
    print("ğŸ”§ MyXTTS GPU Utilization Fix")
    print("=" * 50)
    
    # Check requirements
    if not check_requirements():
        print("âŒ Requirements check failed")
        return
    
    # Show guide
    show_gpu_optimization_guide()
    
    # Interactive menu
    while True:
        print("\nØ§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:")
        print("1. Ø§Ø¬Ø±Ø§ÛŒ benchmark GPU utilization")
        print("2. ØªØ³Øª training Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡")
        print("3. Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„")
        print("4. Ø®Ø±ÙˆØ¬")
        
        choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§ (1-4): ").strip()
        
        if choice == "1":
            run_gpu_benchmark()
        elif choice == "2":
            test_optimized_training()
        elif choice == "3":
            show_gpu_optimization_guide()
        elif choice == "4":
            print("âœ… Ø®Ø±ÙˆØ¬")
            break
        else:
            print("âŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")

if __name__ == "__main__":
    main()