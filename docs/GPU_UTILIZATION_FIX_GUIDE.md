# ğŸ¯ Ø±Ø§Ù‡â€ŒØ­Ù„ Ú©Ø§Ù…Ù„ Ù…Ø³Ø¦Ù„Ù‡ GPU Utilization Ø¯Ø± MyXTTS

## Ù…Ø³Ø¦Ù„Ù‡ Ø´Ù…Ø§
Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§Ù„ training Ø§Ø³Øª ÙˆÙ„ÛŒ GPU utilization Ø¨ÛŒÙ† **40%** Ùˆ **2%** Ù†ÙˆØ³Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§ÛŒÙ† ÛŒØ¹Ù†ÛŒ:
- GPU Ø¨ÛŒØ´ØªØ± ÙˆÙ‚Øª Ù…Ù†ØªØ¸Ø± Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª ØªØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†Ø¯
- Data loading Ú©Ù†Ø¯ Ø§Ø³Øª
- CPU-GPU synchronization Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ø¯
- Memory management Ù†Ø§Ú©Ø§Ø±Ø¢Ù…Ø¯ Ø§Ø³Øª

## ğŸ”§ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡

### 1. GPU Utilization Optimizer
ÙØ§ÛŒÙ„: `gpu_utilization_optimizer.py`
- âœ… Async data prefetching
- âœ… Multi-threaded data loading  
- âœ… GPU memory pool management
- âœ… Real-time monitoring

### 2. Optimized Training Script
ÙØ§ÛŒÙ„: `train_main.py` (updated)
- âœ… Enhanced DataLoader settings
- âœ… GPU monitoring integration
- âœ… Memory management
- âœ… Performance tracking

### 3. Configuration Files
ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡:
- `config_gpu_utilization_optimized.yaml` - ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡
- `train_gpu_optimized.sh` - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø³Ø§Ù†

## ğŸš€ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

### Ø±ÙˆØ´ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¢Ù…Ø§Ø¯Ù‡
```bash
# Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
./train_gpu_optimized.sh
```

### Ø±ÙˆØ´ 2: Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒ Ø¨Ø§ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡
```bash
python3 train_main.py \
    --config config_gpu_utilization_optimized.yaml \
    --model-size tiny \
    --train-data ./data/train.csv \
    --val-data ./data/val.csv \
    --batch-size auto \
    --num-workers auto \
    --optimization-level enhanced
```

### Ø±ÙˆØ´ 3: Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø§ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ú©Ø§Ù…Ù„
```bash
python3 train_main.py \
    --model-size tiny \
    --train-data ./data/train.csv \
    --val-data ./data/val.csv \
    --optimization-level enhanced \
    --apply-fast-convergence \
    --enable-evaluation \
    --batch-size 16 \
    --num-workers 8
```

## ğŸ“Š Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ

### DataLoader Optimizations
```python
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡:
num_workers = 8-16          # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ
prefetch_factor = 4-8       # prefetch Ø¨ÛŒØ´ØªØ±
persistent_workers = True   # workers Ø«Ø§Ø¨Øª
pin_memory = True          # transfer Ø³Ø±ÛŒØ¹â€ŒØªØ±
drop_last = True           # batch size Ø«Ø§Ø¨Øª
multiprocessing_context = 'spawn'  # Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ GPU
```

### GPU Memory Management
```python
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª memory:
memory_fraction = 0.80-0.85    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø² GPU memory
enable_async_prefetch = True   # async data loading
max_prefetch_batches = 8       # queue size
cleanup_interval = 100         # memory cleanup
```

### Real-time Monitoring
```python
# Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø²Ù†Ø¯Ù‡:
monitor_gpu_utilization()     # Ù‡Ø± 50 step
log_memory_usage()           # tracking memory
performance_recommendations() # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø®ÙˆØ¯Ú©Ø§Ø±
```

## ğŸ¯ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±

### Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ:
- GPU Utilization: 40% â†’ 2% â†’ 40% (Ù†Ø§Ù¾Ø§ÛŒØ¯Ø§Ø±)
- Memory Usage: Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡
- Training Speed: Ú©Ù†Ø¯
- Data Loading: bottleneck

### Ø¨Ø¹Ø¯ Ø§Ø² Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ:
- GPU Utilization: **80-95%** (Ù¾Ø§ÛŒØ¯Ø§Ø±)
- Memory Usage: **70-85%** (Ø¨Ù‡ÛŒÙ†Ù‡)
- Training Speed: **2-3x Ø³Ø±ÛŒØ¹â€ŒØªØ±**
- Data Loading: **Ø¨Ø¯ÙˆÙ† ØªØ§Ø®ÛŒØ±**

## ğŸ” Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ùˆ ØªØ´Ø®ÛŒØµ

### Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª GPU:
```bash
# Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± GPU
nvidia-smi -l 1

# Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ utilization
watch -n 1 'nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv'
```

### Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯:
```
ğŸ“Š Step 50: Loss=0.1234, GPU=85%, Memory=72.1%, Time=2.1s
ğŸ“Š Step 100: Loss=0.1156, GPU=87%, Memory=73.5%, Time=2.0s
ğŸ’¡ GPU Optimization Recommendations:
   - GPU utilization stable at 85%
   - Memory usage optimal
```

## âš ï¸ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

### 1. Dataset Path
Ù‚Ø¨Ù„ Ø§Ø² trainingØŒ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ dataset Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ø§Ø³Øª:
```bash
# Ø§ÛŒØ¬Ø§Ø¯ symbolic link ÛŒØ§ copy Ú©Ø±Ø¯Ù† dataset
ln -s /path/to/your/dataset ./data/train.csv
ln -s /path/to/your/valdataset ./data/val.csv
```

### 2. CUDA Memory
Ø§Ú¯Ø± OOM error Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯ÛŒØ¯:
```bash
# Ú©Ø§Ù‡Ø´ batch size
--batch-size 8

# ÛŒØ§ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ gradient checkpointing
--enable-gradient-checkpointing
```

### 3. Workers ØªÙ†Ø¸ÛŒÙ…
```bash
# Auto-detection
--num-workers auto

# ÛŒØ§ manual:
--num-workers 8  # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 2x CPU cores
```

## ğŸ› ï¸ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### Ù…Ø³Ø¦Ù„Ù‡ 1: GPU Utilization Ù‡Ù†ÙˆØ² Ú©Ù… Ø§Ø³Øª
```bash
# Ø§ÙØ²Ø§ÛŒØ´ prefetch
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Ø§ÙØ²Ø§ÛŒØ´ workers
--num-workers 12
```

### Ù…Ø³Ø¦Ù„Ù‡ 2: Memory Error
```bash
# Ú©Ø§Ù‡Ø´ memory fraction
--max-memory-fraction 0.75

# ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ gradient checkpointing
--enable-gradient-checkpointing
```

### Ù…Ø³Ø¦Ù„Ù‡ 3: Data Loading Ú©Ù†Ø¯
```bash
# Ø¨Ø±Ø±Ø³ÛŒ storage speed
dd if=/path/to/dataset of=/dev/null bs=1M count=1000

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SSD Ø¨Ø±Ø§ÛŒ dataset
```

## ğŸ“ˆ ØªØ³Øª Performance

### Ø§Ø¬Ø±Ø§ÛŒ Benchmark:
```python
# ØªØ³Øª GPU optimizer
python3 -c "
from gpu_utilization_optimizer import test_gpu_optimizer
test_gpu_optimizer()
"
```

### Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯:
```bash
# Ù‚Ø¨Ù„: training Ù…Ø¹Ù…ÙˆÙ„ÛŒ
python3 train_main.py --model-size tiny --batch-size 16

# Ø¨Ø¹Ø¯: training Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡
python3 train_main.py --model-size tiny --batch-size 16 --optimization-level enhanced
```

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡

Ø¨Ø§ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÛŒÙ† Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ØŒ Ù…Ø³Ø¦Ù„Ù‡ GPU utilization Ú©Ù‡ Ø¨ÛŒÙ† 40% Ùˆ 2% Ù†ÙˆØ³Ø§Ù† Ù…ÛŒâ€ŒÚ©Ø±Ø¯ Ø­Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯ Ùˆ Ø´Ù…Ø§:

âœ… **GPU utilization Ù¾Ø§ÛŒØ¯Ø§Ø± 80-95%** Ø®ÙˆØ§Ù‡ÛŒØ¯ Ø¯Ø§Ø´Øª  
âœ… **Ø³Ø±Ø¹Øª training 2-3 Ø¨Ø±Ø§Ø¨Ø±** Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯  
âœ… **Memory usage Ø¨Ù‡ÛŒÙ†Ù‡** Ù…ÛŒâ€ŒØ´ÙˆØ¯  
âœ… **Data loading bottleneck** Ø§Ø² Ø¨ÛŒÙ† Ù…ÛŒâ€ŒØ±ÙˆØ¯  
âœ… **Real-time monitoring** Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø±ÛŒØ¯  

Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± data loading Ø±Ø§ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ø±Ø¯Ù‡ Ùˆ GPU Ø±Ø§ Ù…Ø´ØºÙˆÙ„ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ù†Ø¯.