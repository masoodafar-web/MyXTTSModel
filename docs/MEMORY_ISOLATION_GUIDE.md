# Memory-Isolated Producer-Consumer GPU Pipeline Guide

## Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Pipeline ØªÙˆÙ„ÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡-Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¨Ø§ Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡

Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ùˆ-GPU Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

## Overview | Ù…Ø±ÙˆØ±Ú©Ù„ÛŒ

Memory-Isolated Dual-GPU Training ÛŒÚ© Ø§Ù„Ú¯ÙˆÛŒ producer-consumer Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³Øª Ú©Ù‡:

- **Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ø­Ø§ÙØ¸Ù‡** Ø¨ÛŒÙ† GPU Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ GPU Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
- **Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡** Ø§Ø² Ù‡Ø± Ø¯Ùˆ GPU Ø¨Ø§ ØªØ®ØµÛŒØµ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ù†Ø§Ø³Ø¨
- **Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨Ø§Ù„Ø§** Ø¨Ø¯ÙˆÙ† ØªØ¯Ø§Ø®Ù„ Ø­Ø§ÙØ¸Ù‡
- **Ø³Ø±Ø¹Øª 2-3 Ø¨Ø±Ø§Ø¨Ø±ÛŒ** Ù†Ø³Ø¨Øª Ø¨Ù‡ ØªÚ© GPU

## Architecture | Ù…Ø¹Ù…Ø§Ø±ÛŒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Memory-Isolated Producer-Consumer Pipeline      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   GPU 0        â”‚          â”‚   GPU 1          â”‚  â”‚
â”‚  â”‚   (Data GPU)   â”‚  â•â•â•â•â•â•â•>â”‚   (Model GPU)    â”‚  â”‚
â”‚  â”‚                â”‚          â”‚                  â”‚  â”‚
â”‚  â”‚  Memory:       â”‚          â”‚  Memory:         â”‚  â”‚
â”‚  â”‚  8GB Limit     â”‚          â”‚  16GB Limit      â”‚  â”‚
â”‚  â”‚                â”‚          â”‚                  â”‚  â”‚
â”‚  â”‚  â€¢ Load Data   â”‚          â”‚  â€¢ Model Fwd     â”‚  â”‚
â”‚  â”‚  â€¢ Preprocess  â”‚          â”‚  â€¢ Model Bwd     â”‚  â”‚
â”‚  â”‚  â€¢ Augment     â”‚          â”‚  â€¢ Optimization  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†‘                             â†“             â”‚
â”‚         â”‚                             â”‚             â”‚
â”‚         â””â”€â”€â”€ Double Buffering â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features | ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§

### 1. Memory Isolation | Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡

```python
# GPU 0: Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 8GB Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡
# GPU 1: Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 16GB Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„

setup_gpu_memory_isolation(
    data_gpu_id=0,
    model_gpu_id=1,
    data_gpu_memory_limit=8192,  # 8GB
    model_gpu_memory_limit=16384  # 16GB
)
```

### 2. Three-Phase Pipeline | Ø®Ø· Ù„ÙˆÙ„Ù‡ Ø³Ù‡ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ

**Phase 1: Data Processing on GPU 0**
```python
# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±ÙˆÛŒ GPU Ø¯Ø§Ø¯Ù‡
with tf.device('/GPU:0'):
    processed_data = preprocess(raw_data)
```

**Phase 2: Transfer to GPU 1**
```python
# Ø§Ù†ØªÙ‚Ø§Ù„ Ú©Ù†ØªØ±Ù„ Ø´Ø¯Ù‡
with tf.device('/GPU:1'):
    model_data = tf.identity(processed_data)
```

**Phase 3: Training on GPU 1**
```python
# Ø¢Ù…ÙˆØ²Ø´ Ø±ÙˆÛŒ GPU Ù…Ø¯Ù„
with tf.device('/GPU:1'):
    loss = model.train_step(model_data)
```

### 3. Memory Monitoring | Ù†Ø¸Ø§Ø±Øª Ø­Ø§ÙØ¸Ù‡

```python
# Ù†Ø¸Ø§Ø±Øª Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯
log_memory_stats(data_gpu_id=0, model_gpu_id=1)

# ØªØ´Ø®ÛŒØµ Ù†Ø´ØªÛŒ Ø­Ø§ÙØ¸Ù‡
detect_memory_leak(gpu_id=0, baseline_mb=2048)
```

## Usage | Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

### Basic Training | Ø¢Ù…ÙˆØ²Ø´ Ø³Ø§Ø¯Ù‡

```bash
python train_main.py \
    --data-gpu 0 \
    --model-gpu 1 \
    --enable-memory-isolation \
    --train-data ../dataset/dataset_train \
    --val-data ../dataset/dataset_eval
```

### Advanced Configuration | Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

```bash
python train_main.py \
    --data-gpu 0 \
    --model-gpu 1 \
    --enable-memory-isolation \
    --data-gpu-memory 8192 \
    --model-gpu-memory 16384 \
    --batch-size 32 \
    --buffer-size 50 \
    --train-data ../dataset/dataset_train
```

### Custom Memory Limits | Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø³ÙØ§Ø±Ø´ÛŒ

```bash
# Ø¨Ø±Ø§ÛŒ GPU Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ú©Ù…ØªØ±
python train_main.py \
    --data-gpu 0 \
    --model-gpu 1 \
    --enable-memory-isolation \
    --data-gpu-memory 4096 \
    --model-gpu-memory 8192 \
    --batch-size 16
```

## CLI Arguments | Ø¢Ø±Ú¯ÙˆÙ…Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†

| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `--data-gpu` | int | None | Ø´Ù…Ø§Ø±Ù‡ GPU Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ |
| `--model-gpu` | int | None | Ø´Ù…Ø§Ø±Ù‡ GPU Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ |
| `--enable-memory-isolation` | flag | False | ÙØ¹Ø§Ù„Ø³Ø§Ø²ÛŒ Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ |
| `--data-gpu-memory` | int | 8192 | Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø§ÙØ¸Ù‡ GPU Ø¯Ø§Ø¯Ù‡ (MB) |
| `--model-gpu-memory` | int | 16384 | Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø§ÙØ¸Ù‡ GPU Ù…Ø¯Ù„ (MB) |

## Performance Expectations | Ø§Ù†ØªØ¸Ø§Ø±Ø§Øª Ø¹Ù…Ù„Ú©Ø±Ø¯

### GPU Utilization | Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ GPU

- **Data GPU (GPU 0)**: 40-60% Ø§Ø³ØªÙØ§Ø¯Ù‡ (ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡)
- **Model GPU (GPU 1)**: 80-95% Ø§Ø³ØªÙØ§Ø¯Ù‡ (ÙÙ‚Ø· Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„)

### Memory Usage | Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡

- **Data GPU**: 70-90% Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡
- **Model GPU**: 85-95% Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡

### Speed Improvement | Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª

- **vs Single GPU**: 2-3x Ø³Ø±ÛŒØ¹ØªØ±
- **vs Standard Dual-GPU**: 1.3-1.5x Ø³Ø±ÛŒØ¹ØªØ±

## Monitoring | Ù†Ø¸Ø§Ø±Øª

### Real-time Monitoring | Ù†Ø¸Ø§Ø±Øª Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯

```python
# Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø­Ø§ÙØ¸Ù‡
stats = trainer.get_memory_stats()

print(f"Data GPU: {stats['data_gpu']['info']['used_mb']}MB")
print(f"Model GPU: {stats['model_gpu']['info']['used_mb']}MB")
```

### Log Output | Ø®Ø±ÙˆØ¬ÛŒ Ù„Ø§Ú¯

```
[Step 100] Data GPU 0: 5248/8192MB (64.1%)
[Step 100] Model GPU 1: 14336/16384MB (87.5%)
```

## Troubleshooting | Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### Issue: Out of Memory | Ù…Ø´Ú©Ù„: Ú©Ù…Ø¨ÙˆØ¯ Ø­Ø§ÙØ¸Ù‡

**Ø¹Ù„Øª**: Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø®ÛŒÙ„ÛŒ Ú©Ù… Ø§Ø³Øª

**Ø±Ø§Ù‡Ú©Ø§Ø±**:
```bash
# Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø§ÙØ¸Ù‡
python train_main.py \
    --data-gpu 0 \
    --model-gpu 1 \
    --enable-memory-isolation \
    --data-gpu-memory 10240 \
    --model-gpu-memory 20480
```

### Issue: Low GPU Utilization | Ù…Ø´Ú©Ù„: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù… Ø§Ø² GPU

**Ø¹Ù„Øª**: Ø§Ù†Ø¯Ø§Ø²Ù‡ batch Ø®ÛŒÙ„ÛŒ Ú©ÙˆÚ†Ú© Ø§Ø³Øª

**Ø±Ø§Ù‡Ú©Ø§Ø±**:
```bash
# Ø§ÙØ²Ø§ÛŒØ´ batch size
python train_main.py \
    --data-gpu 0 \
    --model-gpu 1 \
    --enable-memory-isolation \
    --batch-size 64
```

### Issue: Memory Leak Detected | Ù…Ø´Ú©Ù„: Ù†Ø´ØªÛŒ Ø­Ø§ÙØ¸Ù‡

**Ø¹Ù„Øª**: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ù¾Ø§Ú© Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯

**Ø±Ø§Ù‡Ú©Ø§Ø±**: Trainer Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± memory cleanup Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Ø§Ù…Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ø³ØªÛŒ Ù†ÛŒØ² Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯:

```python
import gc
import tensorflow as tf

gc.collect()
tf.keras.backend.clear_session()
```

### Issue: "GPU already initialized" | Ù…Ø´Ú©Ù„: "GPU Ù‚Ø¨Ù„Ø§Ù‹ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø´Ø¯Ù‡"

**Ø¹Ù„Øª**: Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² TensorFlow ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´Ø¯Ù‡

**Ø±Ø§Ù‡Ú©Ø§Ø±**: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ `--enable-memory-isolation` Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± Ø¹Ù…Ù„ÛŒØ§Øª TensorFlow Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø§ÛŒÙ† Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± `train_main.py` Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯.

## Advanced Usage | Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡

### Optimal Memory Limits | Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø­Ø§ÙØ¸Ù‡

```python
from myxtts.utils.gpu_memory import get_optimal_memory_limits

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡
data_limit, model_limit = get_optimal_memory_limits(
    data_gpu_id=0,
    model_gpu_id=1,
    data_fraction=0.33,  # 33% Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡
    model_fraction=0.67  # 67% Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
)

print(f"Optimal data GPU limit: {data_limit}MB")
print(f"Optimal model GPU limit: {model_limit}MB")
```

### Custom Trainer | Trainer Ø³ÙØ§Ø±Ø´ÛŒ

```python
from myxtts.training.memory_isolated_trainer import MemoryIsolatedDualGPUTrainer

trainer = MemoryIsolatedDualGPUTrainer(
    config=config,
    data_gpu_id=0,
    model_gpu_id=1,
    data_gpu_memory_limit=8192,
    model_gpu_memory_limit=16384,
    enable_monitoring=True
)

trainer.train(train_dataset, val_dataset, epochs=100)
```

## Best Practices | Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§

1. **Memory Limits**: Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§ÙØ¸Ù‡ Ú©Ù„ GPU ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
   - Data GPU: 30-40% Ø§Ø² Ú©Ù„ Ø­Ø§ÙØ¸Ù‡
   - Model GPU: 60-70% Ø§Ø² Ú©Ù„ Ø­Ø§ÙØ¸Ù‡

2. **Batch Size**: Ø¨Ø§ batch sizeâ€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ± Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯ Ùˆ Ø¯Ø± ØµÙˆØ±Øª OOM Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯
   - Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡: 32-64
   - Ø¨Ø±Ø§ÛŒ GPUâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©: 16-32

3. **Buffer Size**: buffer size Ø¨Ø²Ø±Ú¯ØªØ± Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨Ù‡ØªØ±
   - Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: 50-100
   - Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©: 25-50

4. **Monitoring**: Ù‡Ù…ÛŒØ´Ù‡ monitoring Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯ Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´
   ```python
   enable_monitoring=True
   ```

## Validation | Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ

### Test Setup | ØªØ³Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ

```bash
# Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ memory isolation
python tests/test_memory_isolation.py
```

### Verify Configuration | ØªØ£ÛŒÛŒØ¯ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ

```python
# Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ GPU
python -c "
from myxtts.utils.gpu_memory import get_gpu_memory_info
import pprint
pprint.pprint(get_gpu_memory_info())
"
```

## Performance Metrics | Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯

### Expected Output | Ø®Ø±ÙˆØ¬ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±

```
Memory-Isolated Dual-GPU Trainer Initialization
======================================================================
ğŸ¯ Setting up GPU Memory Isolation...
   Data GPU 0: 8192MB limit
   Model GPU 1: 16384MB limit
   âœ… Data GPU memory limit set to 8192MB
   âœ… Model GPU memory limit set to 16384MB
   âœ… Set visible devices: GPU 0 and GPU 1
   âœ… Enabled memory growth for visible GPU 0
   âœ… Enabled memory growth for visible GPU 1
âœ… GPU Memory Isolation configured successfully

ğŸ¯ Device Mapping:
   Physical GPU 0 â†’ Logical /GPU:0 (Data Processing)
   Physical GPU 1 â†’ Logical /GPU:1 (Model Training)

âœ… Memory-Isolated Dual-GPU Trainer initialized successfully
======================================================================
```

## References | Ù…Ù†Ø§Ø¨Ø¹

- [TensorFlow Multi-GPU Documentation](https://www.tensorflow.org/guide/gpu)
- [Producer-Consumer Pattern](https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem)
- [GPU Memory Management Best Practices](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)

## License | Ù…Ø¬ÙˆØ²

Part of MyXTTS Model - See main project license
