#!/usr/bin/env python3
"""
Demonstration script showing the before and after of the XTTS model
with duration predictor and attention alignment support.
"""

import os
import sys
import numpy as np
import tensorflow as tf

# Add the myxtts package to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from myxtts.models.xtts import XTTS
from myxtts.config.config import XTTSConfig
from myxtts.training.losses import XTTSLoss


def demonstrate_improvements():
    """Demonstrate the improvements made to the XTTS model."""
    print("üéØ XTTS Model Enhancement Demonstration")
    print("=" * 60)
    print("Issue: Model lacked duration predictor and attention alignment outputs")
    print("Solution: Added duration predictor and attention weights for training stability")
    print()
    
    # Create enhanced config
    config = XTTSConfig()
    print("üìä Enhanced Configuration:")
    print(f"   Duration Loss Weight: {config.training.duration_loss_weight}")
    print(f"   Attention Loss Weight: {config.training.attention_loss_weight}")
    print()
    
    # Create model
    model = XTTS(config.model)
    
    # Demo inputs
    batch_size = 1
    text_len = 8
    mel_len = 16
    text_inputs = tf.random.uniform([batch_size, text_len], 0, 50, dtype=tf.int32)
    mel_inputs = tf.random.normal([batch_size, mel_len, config.model.n_mels])
    text_lengths = tf.constant([text_len], dtype=tf.int32)
    mel_lengths = tf.constant([mel_len], dtype=tf.int32)
    
    print("üîç Model Outputs Comparison:")
    print()
    
    # Training mode (NEW - with duration and attention)
    print("üìà Training Mode (Enhanced):")
    train_outputs = model(
        text_inputs=text_inputs,
        mel_inputs=mel_inputs,
        text_lengths=text_lengths,
        mel_lengths=mel_lengths,
        training=True
    )
    
    for key, value in train_outputs.items():
        status = "üÜï NEW" if key in ["duration_pred", "attention_weights"] else "‚úÖ Existing"
        print(f"   {status} {key}: {value.shape}")
    print()
    
    # Inference mode (unchanged)
    print("üöÄ Inference Mode (Compatible):")
    infer_outputs = model(
        text_inputs=text_inputs,
        mel_inputs=mel_inputs,
        text_lengths=text_lengths,
        mel_lengths=mel_lengths,
        training=False
    )
    
    for key, value in infer_outputs.items():
        print(f"   ‚úÖ {key}: {value.shape}")
    print()
    
    # Loss function comparison
    print("üìä Loss Function Enhancement:")
    
    # Create loss function with new capabilities
    loss_fn = XTTSLoss(
        mel_loss_weight=config.training.mel_loss_weight,
        stop_loss_weight=1.0,
        attention_loss_weight=config.training.attention_loss_weight,
        duration_loss_weight=config.training.duration_loss_weight
    )
    
    # Create targets
    targets = {
        "mel_target": tf.random.normal([batch_size, mel_len, config.model.n_mels]),
        "stop_target": tf.concat([
            tf.zeros([batch_size, mel_len-1, 1]),
            tf.ones([batch_size, 1, 1])
        ], axis=1),
        "duration_target": tf.random.uniform([batch_size, text_len], 0.5, 1.5),
        "text_lengths": text_lengths,
        "mel_lengths": mel_lengths
    }
    
    # Compute loss with all components
    total_loss = loss_fn(targets, train_outputs)
    
    print(f"   Total Enhanced Loss: {total_loss.numpy():.4f}")
    
    individual_losses = loss_fn.losses
    for loss_name, loss_value in individual_losses.items():
        status = "üÜï" if loss_name in ["duration_loss", "attention_loss"] else "‚úÖ"
        print(f"   {status} {loss_name}: {loss_value.numpy():.4f}")
    print()
    
    print("üéØ Benefits of the Enhancement:")
    print("   ‚úÖ Duration predictor helps with alignment timing")
    print("   ‚úÖ Attention weights enable monotonic attention loss")
    print("   ‚úÖ Training stability improved through alignment guidance")
    print("   ‚úÖ Reduced repetition and skipping in generated speech")
    print("   ‚úÖ Backward compatible - inference mode unchanged")
    print("   ‚úÖ Loss weights can be tuned for specific use cases")
    print()
    
    print("üîß Technical Implementation:")
    print("   ‚Ä¢ Added duration_predictor Dense layer to TextEncoder")
    print("   ‚Ä¢ Modified MultiHeadAttention to optionally return attention weights")
    print("   ‚Ä¢ Enhanced TransformerBlock to support attention weight extraction")
    print("   ‚Ä¢ Updated MelDecoder to collect cross-attention weights")
    print("   ‚Ä¢ Modified XTTS model to return duration_pred and attention_weights")
    print("   ‚Ä¢ Enabled duration_loss_weight and attention_loss_weight in config")
    print("   ‚Ä¢ Maintained full backward compatibility for inference")
    print()
    
    print("üéâ Issue Resolved!")
    print("   The model now provides duration predictions and attention alignment")
    print("   outputs that the loss functions expect, enabling stable training")
    print("   with reduced repetition and improved convergence.")
    

if __name__ == "__main__":
    demonstrate_improvements()