#!/usr/bin/env python3
"""
Training with Teacher Forcing Monitoring
ØªØ±ÛŒÙ†Ù†Ú¯ Ø¨Ø§ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Teacher Forcing
"""
import os
import sys
import numpy as np
import tensorflow as tf
import soundfile as sf
from datetime import datetime

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù„Ø§Ø²Ù…
sys.path.insert(0, os.path.abspath('.'))

from train_main import build_config
from myxtts.training.trainer import XTTSTrainer
from myxtts.inference.synthesizer import XTTSInference
from myxtts.utils.commons import find_latest_checkpoint

class TeacherForcingMonitor:
    """Monitor teacher forcing performance during training."""
    
    def __init__(self, config, test_audio_path='speaker.wav'):
        self.config = config
        self.test_audio_path = test_audio_path
        self.test_text = "The Chronicles of Newgate, Volume two by Arthur Griffiths."
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØªØ³Øª
        try:
            self.test_audio, sr = sf.read(test_audio_path)
            if self.test_audio.ndim > 1:
                self.test_audio = self.test_audio.mean(axis=1)
            print(f"âœ… Test audio loaded: {test_audio_path}")
        except Exception as e:
            print(f"âŒ Could not load test audio: {e}")
            self.test_audio = None
    
    def evaluate_model(self, model, audio_processor, text_processor, step):
        """Evaluate model using teacher forcing."""
        if self.test_audio is None:
            return None
            
        try:
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†
            processed_text = XTTSInference._preprocess_text(None, self.test_text, self.config.data.language)
            seq = text_processor.text_to_sequence(processed_text)
            text_tensor = tf.constant([seq], dtype=tf.int32)
            text_lengths = tf.constant([len(seq)], dtype=tf.int32)
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª
            audio_processed = audio_processor.preprocess_audio(self.test_audio)
            mel_target = audio_processor.wav_to_mel(audio_processed).T
            mel_tensor = tf.constant(mel_target[np.newaxis, ...], dtype=tf.float32)
            mel_lengths = tf.constant([mel_target.shape[0]], dtype=tf.int32)
            
            # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„
            outputs = model(
                text_inputs=text_tensor,
                mel_inputs=mel_tensor, 
                text_lengths=text_lengths,
                mel_lengths=mel_lengths,
                training=False  # evaluation mode
            )
            
            mel_pred = outputs['mel_output'].numpy()[0]
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø±Ù‡Ø§
            target_stats = {
                'min': float(mel_target.min()),
                'max': float(mel_target.max()),
                'mean': float(mel_target.mean()),
                'std': float(mel_target.std())
            }
            
            pred_stats = {
                'min': float(mel_pred.min()),
                'max': float(mel_pred.max()),
                'mean': float(mel_pred.mean()),
                'std': float(mel_pred.std())
            }
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§Ù‡Ø§
            mae = float(np.mean(np.abs(mel_target - mel_pred)))
            rmse = float(np.sqrt(np.mean((mel_target - mel_pred)**2)))
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª range
            target_range = target_stats['max'] - target_stats['min']
            pred_range = pred_stats['max'] - pred_stats['min']
            range_ratio = pred_range / max(target_range, 1e-8)
            
            results = {
                'step': step,
                'target_stats': target_stats,
                'pred_stats': pred_stats,
                'mae': mae,
                'rmse': rmse,
                'range_ratio': range_ratio
            }
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            print(f"\nğŸ“Š Teacher Forcing Results at Step {step}:")
            print(f"   ğŸ¯ Target: min={target_stats['min']:.3f}, max={target_stats['max']:.3f}, mean={target_stats['mean']:.3f}, std={target_stats['std']:.3f}")
            print(f"   ğŸ¤– Pred:   min={pred_stats['min']:.3f}, max={pred_stats['max']:.3f}, mean={pred_stats['mean']:.3f}, std={pred_stats['std']:.3f}")
            print(f"   ğŸ“ˆ Errors: MAE={mae:.3f}, RMSE={rmse:.3f}")
            print(f"   ğŸ“ Range ratio: {range_ratio:.3f} ({'âœ… Good' if range_ratio > 0.5 else 'âŒ Poor'})")
            
            return results
            
        except Exception as e:
            print(f"âŒ Teacher forcing evaluation failed: {e}")
            return None

def train_with_monitoring():
    """Main training function with teacher forcing monitoring."""
    
    print("ğŸš€ Starting Training with Teacher Forcing Monitoring")
    print("=" * 60)
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø§Ø¯Ù‡
    config = build_config(
        model_size='normal',
        checkpoint_dir='./checkpointsmain',
        batch_size=8,
        lr=0.0001,
        epochs=20
    )
    
    # ØªÙ†Ø¸ÛŒÙ… GPU
    tf.config.experimental.set_memory_growth(
        tf.config.list_physical_devices('GPU')[0], True
    )
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† checkpoint
    latest_checkpoint = find_latest_checkpoint('./checkpointsmain')
    print(f"ğŸ“¦ Starting from checkpoint: {latest_checkpoint}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ trainer
    trainer = XTTSTrainer(config=config)
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ checkpoint Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
    if latest_checkpoint and os.path.exists(f"{latest_checkpoint}_model.weights.h5"):
        trainer.load_checkpoint(latest_checkpoint)
        print(f"âœ… Loaded checkpoint: {latest_checkpoint}")
    else:
        print("ğŸ†• Starting fresh training")
    
    # Ø§ÛŒØ¬Ø§Ø¯ teacher forcing monitor
    monitor = TeacherForcingMonitor(config)
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ±ÛŒÙ†Ù†Ú¯
    max_steps = 2000  # Ú©Ù… Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹
    eval_interval = 200  # Ù‡Ø± 200 Ù‚Ø¯Ù… Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†
    save_interval = 500  # Ù‡Ø± 500 Ù‚Ø¯Ù… Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
    
    print(f"ğŸ¯ Training Settings:")
    print(f"   â€¢ Max steps: {max_steps}")
    print(f"   â€¢ Eval interval: {eval_interval}")
    print(f"   â€¢ Save interval: {save_interval}")
    print(f"   â€¢ Batch size: {getattr(config.training, 'batch_size', 8)}")
    print(f"   â€¢ Learning rate: {getattr(config.training, 'learning_rate', 0.0001)}")
    
    # Ø´Ø±ÙˆØ¹ Ø­Ù„Ù‚Ù‡ ØªØ±ÛŒÙ†Ù†Ú¯ - Ø´Ø±ÙˆØ¹ Ù…Ø¬Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª teacher forcing
    step = 0  # Ø´Ø±ÙˆØ¹ Ø§Ø² ØµÙØ± Ø¨Ø±Ø§ÛŒ monitoring
    
    try:
        while step < max_steps:
            # Ù‚Ø¯Ù… ØªØ±ÛŒÙ†Ù†Ú¯
            train_losses = trainer.train_step()
            step += 1
            
            # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† loss
            if step % 50 == 0:
                mel_loss = train_losses.get('mel_loss', 0.0)
                total_loss = train_losses.get('total_loss', 0.0)
                print(f"Step {step:5d}: mel_loss={mel_loss:.4f}, total_loss={total_loss:.4f}")
            
            # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ teacher forcing
            if step % eval_interval == 0:
                print(f"\nğŸ” Evaluating Teacher Forcing at Step {step}")
                results = monitor.evaluate_model(
                    trainer.model,
                    trainer.audio_processor,
                    trainer.text_processor,
                    step
                )
                
                # Ú†Ú© Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´Ø±ÙØª
                if results:
                    if results['range_ratio'] > 0.3:
                        print("ğŸ‰ Model is starting to learn mel spectrograms!")
                    if results['mae'] < 3.0:
                        print("ğŸ‰ Error is decreasing significantly!")
            
            # Ø°Ø®ÛŒØ±Ù‡ checkpoint
            if step % save_interval == 0:
                checkpoint_path = f"./checkpointsmain/recovery_checkpoint_{step}"
                trainer.save_checkpoint(checkpoint_path)
                print(f"ğŸ’¾ Saved checkpoint: {checkpoint_path}")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Training interrupted by user")
    except Exception as e:
        print(f"\nâŒ Training error: {e}")
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    print(f"\nğŸ Final Evaluation at Step {step}")
    final_results = monitor.evaluate_model(
        trainer.model,
        trainer.audio_processor, 
        trainer.text_processor,
        step
    )
    
    if final_results:
        if final_results['range_ratio'] > 0.5 and final_results['mae'] < 2.0:
            print("ğŸ‰ SUCCESS: Model has learned to generate proper mel spectrograms!")
            print("   Ready for inference testing.")
        else:
            print("âš ï¸  Model still needs more training.")
            print("   Consider continuing training or adjusting hyperparameters.")

if __name__ == "__main__":
    train_with_monitoring()