# ÿ±ÿßŸá⁄©ÿßÿ± ŸÜŸáÿß€å€å ÿ®ÿ±ÿß€å ŸÖÿ¥⁄©ŸÑ ÿßÿ≥ÿ™ŸÅÿßÿØŸá 1-5% GPU ÿØÿ± Dual-RTX-4090
# Critical Fix for 1-5% GPU Utilization Issue on Dual RTX 4090

## üî¥ ŸÖÿ¥⁄©ŸÑ ÿ¥ŸÜÿßÿ≥ÿß€å€å ÿ¥ÿØŸá / Identified Problem

**Symptoms:**
- GPU utilization oscillating between 1-5% during training
- Both RTX 4090 GPUs severely underutilized
- Training extremely slow despite all previous optimizations
- High RAM and GPU memory usage but low compute utilization

**Previous Optimizations Applied (but insufficient):**
- ‚úÖ TF-native data loading
- ‚úÖ Triple buffering
- ‚úÖ Async pipeline
- ‚úÖ High prefetch (100+)
- ‚úÖ Memory isolation
- ‚úÖ XLA JIT enabled

## üîç ÿ±€åÿ¥Ÿá‚Äå€åÿßÿ®€å ÿπŸÖ€åŸÇ / Deep Root Cause Analysis

After comprehensive code analysis, the following critical issues were identified:

### 1. **Insufficient Data Pipeline Parallelism**
Despite TF-native loading, the data pipeline lacks aggressive parallelism settings:
- `num_parallel_calls` not set to maximum
- Dataset options not fully optimized
- Missing `experimental_optimization` flags

### 2. **Critical TensorFlow Performance Flags Missing**
Several critical TensorFlow optimization flags are not enabled:
- `tf.data.experimental.AUTOTUNE` not used everywhere
- `experimental_determinism=False` not set
- `experimental_optimization.map_parallelization` not enabled
- Missing `experimental_optimization.parallel_batch` settings

### 3. **Batch Preparation Bottleneck**
- Batch preparation is not fully pipelined
- Missing explicit parallelization in batch assembly
- No asynchronous batch prefetching

### 4. **Inadequate TensorFlow Thread Configuration**
TensorFlow thread pools not configured for dual-GPU high-throughput:
- `inter_op_parallelism_threads` not optimized
- `intra_op_parallelism_threads` not set
- Missing parallel iteration configuration

### 5. **Dataset Iterator Inefficiency**
The dataset iterator may be creating synchronization points:
- Not using `experimental_fetch_to_device` aggressively enough
- Missing parallel interleave for data loading
- Insufficient prefetching to GPU

## üîß ÿ±ÿßŸá⁄©ÿßÿ± ÿ¨ÿßŸÖÿπ / Comprehensive Solution

### Phase 1: Aggressive TensorFlow Configuration

**File: `myxtts/data/ljspeech.py`**

Add aggressive TensorFlow thread configuration:

```python
def _configure_tensorflow_for_max_throughput():
    """Configure TensorFlow for maximum throughput on dual-GPU."""
    import os
    
    # Get CPU count for optimal threading
    cpu_count = os.cpu_count() or 16
    
    # Configure thread pools for maximum throughput
    # inter_op: threads for independent operations
    # intra_op: threads within operations
    tf.config.threading.set_inter_op_parallelism_threads(cpu_count)
    tf.config.threading.set_intra_op_parallelism_threads(cpu_count // 2)
    
    # Enable all experimental optimizations
    options = tf.data.Options()
    options.experimental_optimization.apply_default_optimizations = True
    options.experimental_optimization.autotune = True
    options.experimental_optimization.map_and_batch_fusion = True
    options.experimental_optimization.map_parallelization = True
    options.experimental_optimization.parallel_batch = True
    options.experimental_optimization.noop_elimination = True
    options.experimental_deterministic = False  # Allow reordering for speed
    
    return options
```

### Phase 2: Ultra-Aggressive Data Pipeline

**Modify `create_tf_dataset` method:**

```python
def create_tf_dataset(self, ...):
    # ... existing code ...
    
    # CRITICAL: Apply aggressive optimization options
    options = self._configure_tensorflow_for_max_throughput()
    dataset = dataset.with_options(options)
    
    # Use MAXIMUM parallelism
    num_parallel_calls = tf.data.AUTOTUNE  # Let TF auto-tune to maximum
    
    # ... existing mapping code ...
    
    # CRITICAL: Apply aggressive prefetching at MULTIPLE stages
    # Stage 1: Prefetch after mapping (before batching)
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
    
    # Apply filtering
    dataset = dataset.filter(...)
    
    # CRITICAL: Prefetch again after filtering
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
    
    # Apply batching
    dataset = dataset.padded_batch(...)
    
    # CRITICAL: Aggressive prefetch after batching
    # This is the most important prefetch for GPU feeding
    prefetch_multiplier = 10  # Aggressive prefetch
    buffer_size = max(tf.data.AUTOTUNE, batch_size * prefetch_multiplier)
    dataset = dataset.prefetch(buffer_size)
    
    # Apply repeat last to avoid boundary stalls
    if repeat:
        dataset = dataset.repeat()
    
    # CRITICAL: Final GPU prefetch with maximum buffer
    if getattr(self.config, 'prefetch_to_gpu', True):
        gpus = tf.config.list_logical_devices('GPU')
        if gpus:
            # Use massive buffer for GPU prefetch
            gpu_buffer_size = max(50, batch_size * 20)
            dataset = dataset.apply(
                tf.data.experimental.prefetch_to_device(
                    '/GPU:0',  # Data GPU
                    buffer_size=gpu_buffer_size
                )
            )
    
    # CRITICAL: One more host-side prefetch for safety
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    
    return dataset
```

### Phase 3: Optimize Memory-Isolated Trainer

**File: `myxtts/training/memory_isolated_trainer.py`**

Add aggressive batch prefetching:

```python
class MemoryIsolatedDualGPUTrainer(XTTSTrainer):
    
    def __init__(self, ...):
        # ... existing code ...
        
        # CRITICAL: Increase buffer size significantly
        self.max_buffer_size = 10  # Increase from 3 to 10 buffers
        self.buffer_queue = queue.Queue(maxsize=self.max_buffer_size)
        
        # CRITICAL: Increase pipeline depth
        self.pipeline_depth = 5  # Increase from 2 to 5 batches ahead
        
        # Start aggressive prefetch thread
        self._start_aggressive_prefetch_thread()
    
    def _start_aggressive_prefetch_thread(self):
        """Start background thread for aggressive batch prefetching."""
        def prefetch_worker():
            while self.training:
                try:
                    if not self.buffer_queue.full():
                        # Prefetch multiple batches ahead
                        batch = next(self.dataset_iterator)
                        self.buffer_queue.put(batch, timeout=1.0)
                except Exception:
                    pass
        
        self.prefetch_thread = threading.Thread(
            target=prefetch_worker,
            daemon=True
        )
        self.prefetch_thread.start()
```

### Phase 4: Configuration Changes

**File: `configs/config.yaml`**

```yaml
data:
  # CRITICAL: Aggressive batch size for dual RTX 4090
  batch_size: 128  # Increase significantly from 56
  
  # CRITICAL: Maximum workers for data pipeline
  num_workers: 32  # Increase from 16
  
  # CRITICAL: Aggressive prefetch settings
  prefetch_buffer_size: 100  # Very high prefetch
  shuffle_buffer_multiplier: 50  # Increase from 20
  
  # CRITICAL: Enable all optimizations
  use_tf_native_loading: true
  prefetch_to_gpu: true
  enhanced_gpu_prefetch: true
  optimize_cpu_gpu_overlap: true
  auto_tune_performance: true
  
  # CRITICAL: Enable aggressive TensorFlow optimizations
  enable_xla: true
  mixed_precision: true  # Enable for RTX 4090
  pin_memory: true
  persistent_workers: true
  
  # Memory-isolated dual-GPU settings
  pipeline_buffer_size: 100  # Increase from 50
```

### Phase 5: Runtime Configuration Script

**Create: `utilities/configure_max_gpu_utilization.py`**

```python
#!/usr/bin/env python3
"""
Configure TensorFlow and system for maximum GPU utilization.
Run this before training to ensure optimal settings.
"""

import os
import tensorflow as tf

def configure_max_gpu_utilization():
    """Apply all optimizations for maximum GPU utilization."""
    
    # 1. TensorFlow thread configuration
    cpu_count = os.cpu_count() or 16
    tf.config.threading.set_inter_op_parallelism_threads(cpu_count)
    tf.config.threading.set_intra_op_parallelism_threads(cpu_count // 2)
    
    # 2. GPU memory configuration
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        for gpu in gpus:
            # Enable memory growth
            tf.config.experimental.set_memory_growth(gpu, True)
            
            # Set aggressive memory limit (90% of GPU)
            tf.config.set_logical_device_configuration(
                gpu,
                [tf.config.LogicalDeviceConfiguration(memory_limit=21504)]  # 21GB for RTX 4090
            )
    
    # 3. Enable all TensorFlow optimizations
    tf.config.optimizer.set_jit(True)  # XLA
    tf.config.optimizer.set_experimental_options({
        'layout_optimizer': True,
        'constant_folding': True,
        'shape_optimization': True,
        'remapping': True,
        'arithmetic_optimization': True,
        'dependency_optimization': True,
        'loop_optimization': True,
        'function_optimization': True,
        'debug_stripper': True,
        'disable_model_pruning': False,
        'scoped_allocator_optimization': True,
        'pin_to_host_optimization': True,
        'implementation_selector': True,
        'auto_mixed_precision': True,
        'min_graph_nodes': -1  # No minimum for optimization
    })
    
    # 4. Environment variables for maximum performance
    os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'
    os.environ['TF_GPU_THREAD_COUNT'] = str(cpu_count)
    os.environ['TF_SYNC_ON_FINISH'] = '0'  # Async execution
    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
    os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE'] = 'true'
    
    print("‚úÖ Maximum GPU utilization configuration applied")
    print(f"   - CPU threads: {cpu_count} (inter), {cpu_count//2} (intra)")
    print(f"   - GPUs configured: {len(gpus)}")
    print(f"   - XLA JIT: Enabled")
    print(f"   - Mixed Precision: Enabled")
    print(f"   - Memory Growth: Enabled")

if __name__ == "__main__":
    configure_max_gpu_utilization()
```

## üìä ŸÜÿ™ÿß€åÿ¨ ŸÖŸàÿ±ÿØ ÿßŸÜÿ™ÿ∏ÿßÿ± / Expected Results

### Before (Current State):
- üî¥ GPU:0 utilization: 1-5%
- üî¥ GPU:1 utilization: 1-5%
- üî¥ Training speed: Extremely slow
- üî¥ Step time: Very high variance

### After (With All Fixes):
- ‚úÖ GPU:0 utilization: 60-80% (data preprocessing)
- ‚úÖ GPU:1 utilization: 85-95% (model training)
- ‚úÖ Training speed: 10-20x faster
- ‚úÖ Step time: Low variance, consistent

## üöÄ ÿØÿ≥ÿ™Ÿàÿ±ÿßŸÑÿπŸÖŸÑ ÿßÿ¨ÿ±ÿß / Implementation Instructions

### Step 1: Apply Code Changes

```bash
# Update ljspeech.py with aggressive pipeline optimizations
# Update memory_isolated_trainer.py with increased buffers
# Update config.yaml with aggressive settings
```

### Step 2: Configure Runtime

```bash
# Run configuration script
python utilities/configure_max_gpu_utilization.py
```

### Step 3: Test Training

```bash
# Test with memory-isolated dual-GPU training
python train_main.py \
    --train-data ../dataset/dataset_train \
    --val-data ../dataset/dataset_eval \
    --batch-size 128 \
    --num-workers 32 \
    --enable-memory-isolation \
    --data-gpu 0 \
    --model-gpu 1 \
    --data-gpu-memory 10240 \
    --model-gpu-memory 20480 \
    --enable-static-shapes \
    --optimization-level enhanced
```

### Step 4: Monitor GPU Utilization

```bash
# In another terminal, monitor GPU usage
watch -n 1 nvidia-smi
```

## üîß ÿπ€åÿ®€åÿßÿ®€å / Troubleshooting

### If GPU utilization is still low (<50%):

1. **Check batch size:**
   ```bash
   # Try even larger batch size
   python train_main.py --batch-size 256 ...
   ```

2. **Check num_workers:**
   ```bash
   # Ensure enough data loading workers
   python train_main.py --num-workers 48 ...
   ```

3. **Verify TF-native loading:**
   Check training logs for:
   ```
   ‚úÖ SUCCESS: Using TensorFlow-native data loading (GPU-optimized)
   ```

4. **Check for data starvation:**
   ```bash
   # Run profiler
   python utilities/dual_gpu_bottleneck_profiler.py --batch-size 128 --num-steps 100
   ```

5. **Verify GPU memory is not exhausted:**
   - If OOM, reduce batch size incrementally
   - Adjust data_gpu_memory and model_gpu_memory limits

## üìà ÿπŸÖŸÑ⁄©ÿ±ÿØ ŸÖŸàÿ±ÿØ ÿßŸÜÿ™ÿ∏ÿßÿ± / Expected Performance Metrics

**Target Metrics:**
- GPU:0 (Data) Utilization: **60-80%**
- GPU:1 (Model) Utilization: **85-95%**
- Step Time: **<0.5 seconds** (with batch_size=128)
- Throughput: **>200 samples/second**
- GPU Memory: **16-20GB used on GPU:1**

**Warning Signs:**
- ‚ö†Ô∏è GPU utilization <50%: Data pipeline bottleneck
- ‚ö†Ô∏è GPU memory <10GB: Batch size too small
- ‚ö†Ô∏è Step time >1s: Configuration issue

## üìù €åÿßÿØÿØÿßÿ¥ÿ™‚ÄåŸáÿß€å ŸÖŸáŸÖ / Important Notes

1. **ÿß€åŸÜ ÿ™ŸÜÿ∏€åŸÖÿßÿ™ ÿ®ÿ±ÿß€å RTX 4090 ÿ®Ÿá€åŸÜŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™**
   These settings are optimized for RTX 4090 GPUs

2. **batch_size ÿ®ÿß€åÿØ ÿ®Ÿá ÿ™ÿØÿ±€åÿ¨ ÿßŸÅÿ≤ÿß€åÿ¥ €åÿßÿ®ÿØ**
   Batch size should be increased gradually to avoid OOM

3. **num_workers ÿ®ÿ≥ÿ™Ÿá ÿ®Ÿá ÿ™ÿπÿØÿßÿØ CPU cores ÿ®ÿß€åÿØ ÿ™ŸÜÿ∏€åŸÖ ÿ¥ŸàÿØ**
   num_workers should be adjusted based on CPU cores

4. **ŸÖÿßŸÜ€åÿ™Ÿàÿ±€åŸÜ⁄Ø ŸÖÿØÿßŸàŸÖ ÿØÿ± epoch ÿßŸàŸÑ ÿ∂ÿ±Ÿàÿ±€å ÿßÿ≥ÿ™**
   Continuous monitoring during first epoch is critical

5. **ÿß⁄Øÿ± OOM ÿ±ÿÆ ÿØÿßÿØÿå batch_size ÿ±ÿß ⁄©ÿßŸáÿ¥ ÿØŸá€åÿØ**
   If OOM occurs, reduce batch_size incrementally

---

**ÿ™ÿßÿ±€åÿÆ / Date:** 2025-10-10
**ŸÜÿ≥ÿÆŸá / Version:** 3.0 - Critical GPU Utilization Fix
**Ÿàÿ∂ÿπ€åÿ™ / Status:** Ready for Implementation
