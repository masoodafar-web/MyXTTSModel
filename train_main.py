#!/usr/bin/env python3
"""
Enhanced MyXTTS Training Script with Large Model Architecture and Advanced Voice Cloning

This training script addresses the Persian problem statement:
"Ù†Ú¯Ø§Ù‡ Ú©Ù† Ø¨Ø¨ÛŒÙ† Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒ Ù†ÛŒØ§Ø² Ù‡Ø³Øª Ø¨Ø¯ÛŒ Ùˆ Ø§ÛŒÙ† Ú©Ù‡ Ù…Ø¯Ù„Ù… Ø±Ùˆ Ø¨Ø²Ø±Ú¯ØªØ± Ú©Ù†ÛŒ Ú©ÛŒÙÛŒØªØ´ Ø¨Ù‡ØªØ± Ø¨Ø´Ù‡ Ùˆ Ø§ÛŒÙ†Ú©Ù‡ Ø¨ØªÙˆÙ†Ù‡ ØµØ¯Ø§ Ø±Ùˆ Ú©Ù„ÙˆÙ† Ø¨Ú©Ù†Ù‡"
(Look and see if other improvements are needed and make my model larger so its quality is better and it can clone voices)

LATEST IMPROVEMENTS APPLIED:
===========================

1. LARGER MODEL ARCHITECTURE FOR HIGHER QUALITY:
   - Text encoder layers: 4 â†’ 8 (better text understanding)
   - Audio encoder dimensions: 512 â†’ 768 (enhanced audio representation)
   - Audio encoder layers: 4 â†’ 8 (deeper audio processing)
   - Audio encoder heads: 4 â†’ 12 (better attention patterns)
   - Decoder dimensions: 512 â†’ 1536 (significantly larger for higher quality)
   - Decoder layers: 6 â†’ 16 (more complex modeling capability)
   - Decoder heads: 8 â†’ 24 (enhanced attention patterns)

2. ADVANCED VOICE CLONING CAPABILITIES:
   - Speaker embedding: 256 â†’ 512 dimensions (better voice representation)
   - Voice conditioning layers: 4 (dedicated voice processing)
   - Voice similarity threshold: 0.75 (quality control)
   - Voice adaptation: Enabled (adaptive conditioning)
   - Speaker interpolation: Enabled (voice blending)
   - Voice denoising: Enabled (cleaner reference audio)
   - Voice cloning loss components: 5 specialized losses

3. ENHANCED LOSS FUNCTIONS FOR VOICE CLONING:
   - Voice similarity loss weight: 3.0 (primary voice matching)
   - Speaker classification loss: 1.5 (speaker identity)
   - Voice reconstruction loss: 2.0 (voice quality)
   - Prosody matching loss: 1.0 (natural speech patterns)
   - Spectral consistency loss: 1.5 (audio quality)

3. ADVANCED TRAINING FEATURES:
   - Scheduler: noam â†’ cosine_with_restarts (better convergence)
   - Gradient clipping: 1.0 â†’ 0.8 (tighter stability)
   - Warmup steps: 2000 â†’ 1500 (faster ramp-up)
   - Adaptive loss weights (auto-adjusting during training)
   - Label smoothing for better generalization
   - Huber loss for robustness
   - Early stopping with increased patience

4. OPTIMIZATION LEVELS:
   - basic: Original parameters for compatibility
   - enhanced: Recommended optimizations (default)
   - experimental: Bleeding-edge features

5. INTEGRATION WITH OPTIMIZATION MODULES:
   - fast_convergence_config: Fast convergence optimizations
   - enhanced_loss_config: Advanced loss configurations
   - enhanced_training_monitor: Real-time training monitoring

EXPECTED BENEFITS:
==================
- SIGNIFICANTLY HIGHER QUALITY: Larger model produces much better audio quality
- SUPERIOR VOICE CLONING: Advanced voice conditioning for accurate voice replication
- FASTER CONVERGENCE: 2-3x faster loss convergence with optimized parameters
- BETTER VOICE SIMILARITY: Enhanced voice matching and speaker identity preservation
- STABLE TRAINING: Reduced oscillations and better gradient flow
- MEMORY OPTIMIZED: Efficient training despite larger model size
- MULTILINGUAL SUPPORT: Enhanced text understanding across 16 languages

VOICE CLONING CAPABILITIES:
===========================
- High-fidelity voice replication from reference audio
- Voice adaptation and interpolation
- Speaker identity preservation
- Prosody and intonation matching
- Spectral consistency maintenance
- Voice denoising for cleaner input

USAGE:
======
Basic (recommended):
  python train_main.py --train-data ../dataset/dataset_train --val-data ../dataset/dataset_eval

With optimization levels:
  python train_main.py --optimization-level enhanced --train-data ../dataset/dataset_train
  python train_main.py --optimization-level experimental --apply-fast-convergence

Legacy compatibility:
  python train_main.py --optimization-level basic --train-data ../dataset/dataset_train
"""

import os
import sys
import argparse
from typing import Optional

os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "3")
os.environ.setdefault("TF_FORCE_GPU_ALLOW_GROWTH", "true")

import tensorflow as tf

from myxtts.config.config import XTTSConfig, ModelConfig, DataConfig, TrainingConfig
from myxtts.models.xtts import XTTS
from myxtts.training.trainer import XTTSTrainer
from myxtts.utils.commons import setup_logging, find_latest_checkpoint
from memory_optimizer import get_gpu_memory_info, get_recommended_settings


# Presets to quickly scale the architecture while keeping components balanced
MODEL_SIZE_PRESETS = {
    "tiny": {
        "text_encoder_dim": 256,
        "text_encoder_layers": 4,
        "text_head_dim": 64,
        "audio_encoder_dim": 256,
        "audio_encoder_layers": 4,
        "audio_head_dim": 64,
        "decoder_dim": 768,
        "decoder_layers": 8,
        "decoder_head_dim": 64,
        "speaker_embedding_dim": 256,
        "voice_conditioning_layers": 2,
        "voice_feature_dim": 128,
        "max_attention_len": 256,
        "max_text_length": 320,
        "enable_gradient_checkpointing": True,
        "description": "Minimum footprint for quick experiments",
    },
    "small": {
        "text_encoder_dim": 384,
        "text_encoder_layers": 6,
        "text_head_dim": 64,
        "audio_encoder_dim": 512,
        "audio_encoder_layers": 6,
        "audio_head_dim": 64,
        "decoder_dim": 1024,
        "decoder_layers": 12,
        "decoder_head_dim": 64,
        "speaker_embedding_dim": 320,
        "voice_conditioning_layers": 3,
        "voice_feature_dim": 192,
        "max_attention_len": 384,
        "max_text_length": 420,
        "enable_gradient_checkpointing": True,
        "description": "Balanced quality vs. speed",
    },
    "normal": {
        "text_encoder_dim": 512,
        "text_encoder_layers": 8,
        "text_head_dim": 64,
        "audio_encoder_dim": 768,
        "audio_encoder_layers": 8,
        "audio_head_dim": 64,
        "decoder_dim": 1536,
        "decoder_layers": 16,
        "decoder_head_dim": 64,
        "speaker_embedding_dim": 512,
        "voice_conditioning_layers": 4,
        "voice_feature_dim": 256,
        "max_attention_len": 512,
        "max_text_length": 500,
        "enable_gradient_checkpointing": True,
        "description": "Enhanced default with full feature set",
    },
    "big": {
        "text_encoder_dim": 768,
        "text_encoder_layers": 10,
        "text_head_dim": 64,
        "audio_encoder_dim": 1024,
        "audio_encoder_layers": 10,
        "audio_head_dim": 64,
        "decoder_dim": 2048,
        "decoder_layers": 20,
        "decoder_head_dim": 64,
        "speaker_embedding_dim": 640,
        "voice_conditioning_layers": 5,
        "voice_feature_dim": 320,
        "max_attention_len": 768,
        "max_text_length": 600,
        "enable_gradient_checkpointing": True,
        "description": "Maximum capacity for highest quality",
    },
}

# Import optimization modules for model improvements
try:
    from fast_convergence_config import create_optimized_config
    from enhanced_loss_config import FastConvergenceOptimizer
    from enhanced_training_monitor import EnhancedTrainingMonitor
    OPTIMIZATION_MODULES_AVAILABLE = True
except ImportError as e:
    OPTIMIZATION_MODULES_AVAILABLE = False
    print(f"Warning: Optimization modules not available: {e}")

# Import new evaluation and optimization features
try:
    from myxtts.evaluation import TTSEvaluator
    from myxtts.optimization import ModelCompressor, CompressionConfig
    from myxtts.optimization.compression import create_lightweight_config
    EVAL_OPT_AVAILABLE = True
except ImportError as e:
    EVAL_OPT_AVAILABLE = False
    print(f"Warning: Evaluation and optimization modules not available: {e}")


def apply_optimization_level(config: XTTSConfig, level: str, args) -> XTTSConfig:
    """
    Apply optimization level to the configuration.
    
    Args:
        config: Base configuration
        level: Optimization level ("basic", "enhanced", "experimental")
        args: Command line arguments
        
    Returns:
        Optimized configuration
    """
    logger = setup_logging()
    
    if level == "basic":
        # Fixed parameters for stable training (addresses "Ù„Ø§Ø³ Ø³Ù‡ Ø±Ù‚Ù…ÛŒÙ‡" issue)
        config.training.learning_rate = 5e-5
        config.training.mel_loss_weight = 2.5   # Fixed from 45.0 - was causing three-digit loss
        config.training.kl_loss_weight = 1.0
        config.training.weight_decay = 1e-6
        config.training.gradient_clip_norm = 1.0
        config.training.warmup_steps = 2000
        config.training.scheduler = "noam"
        logger.info("âœ… Applied BASIC optimization level (original parameters)")
        return config
    
    elif level == "enhanced":
        # Enhanced optimizations - apply cosine restarts scheduler
        config.training.scheduler = "cosine"  # Use cosine scheduler
        config.training.cosine_restarts = True
        config.training.scheduler_params = {
            "min_learning_rate": 1e-7,
            "restart_period": 8000,
            "restart_mult": 0.8,
        }
        logger.info("âœ… Applied ENHANCED optimization level (recommended optimizations)")
        logger.info("Key improvements:")
        logger.info(f"   â€¢ Learning rate: {config.training.learning_rate}")
        logger.info(f"   â€¢ Mel loss weight: {config.training.mel_loss_weight}")
        logger.info(f"   â€¢ Scheduler: {config.training.scheduler} with restarts")
        logger.info(f"   â€¢ Adaptive loss weights: {config.training.use_adaptive_loss_weights}")
        logger.info(f"   â€¢ Label smoothing: {config.training.use_label_smoothing}")
        logger.info(f"   â€¢ Huber loss: {config.training.use_huber_loss}")
        return config
    
    elif level == "experimental" and OPTIMIZATION_MODULES_AVAILABLE:
        # Apply bleeding-edge optimizations from optimization modules
        try:
            optimizer = FastConvergenceOptimizer()
            enhanced_config = optimizer.create_enhanced_training_config()
            
            # Apply experimental enhancements
            for key, value in enhanced_config.items():
                if hasattr(config.training, key):
                    setattr(config.training, key, value)
                    
            logger.info("âœ… Applied EXPERIMENTAL optimization level")
            logger.info("Advanced features applied:")
            logger.info("   â€¢ Dynamic loss scaling")
            logger.info("   â€¢ Enhanced gradient monitoring")
            logger.info("   â€¢ Advanced loss functions")
            logger.info("   â€¢ Convergence tracking")
            
        except Exception as e:
            logger.warning(f"Could not apply experimental optimizations: {e}")
            logger.info("Falling back to enhanced optimization level")
            
        return config
    
    else:
        logger.warning(f"Unknown optimization level '{level}' or modules unavailable")
        logger.info("Using enhanced optimization level as fallback")
        return config


def apply_fast_convergence_config(config: XTTSConfig) -> XTTSConfig:
    """
    Apply fast convergence optimizations from the fast_convergence_config module.
    
    Args:
        config: Base configuration
        
    Returns:
        Configuration with fast convergence optimizations
    """
    logger = setup_logging()
    
    if not OPTIMIZATION_MODULES_AVAILABLE:
        logger.warning("Fast convergence config module not available")
        return config
    
    try:
        # Get optimized configuration
        optimized = create_optimized_config()
        training_opts = optimized['training']
        
        # Apply training optimizations
        for key, value in training_opts.items():
            if hasattr(config.training, key):
                setattr(config.training, key, value)
        
        logger.info("âœ… Applied fast convergence optimizations")
        logger.info(f"   â€¢ Learning rate: {config.training.learning_rate}")
        logger.info(f"   â€¢ Loss weights optimized for convergence")
        logger.info(f"   â€¢ Advanced scheduler with restarts")
        logger.info(f"   â€¢ Enhanced loss stability features")
        
    except Exception as e:
        logger.error(f"Failed to apply fast convergence config: {e}")
    
    return config


def build_config(
    batch_size: int = 32,
    grad_accum: int = 2,
    num_workers: int = 8,
    epochs: int = 500,
    lr: float = 8e-5,
    checkpoint_dir: str = "./checkpointsmain",
    text_dim_override: Optional[int] = None,
    decoder_dim_override: Optional[int] = None,
    max_attention_len_override: Optional[int] = None,
    enable_grad_checkpointing_override: Optional[bool] = None,
    max_memory_fraction: float = 0.9,
    prefetch_buffer_size: int = 12,
    shuffle_buffer_multiplier: int = 30,
    decoder_strategy: str = "autoregressive",
    vocoder_type: str = "griffin_lim",
    model_size: str = "normal",
    # GST parameters for prosody controllability
    enable_gst: bool = True,
    gst_num_style_tokens: int = 10,
    gst_style_token_dim: int = 256,
    gst_style_embedding_dim: int = 256,
    gst_num_heads: int = 4,
    gst_style_loss_weight: float = 1.0,
    # Evaluation parameters for automatic checkpoint quality monitoring
    enable_automatic_evaluation: bool = False,
    evaluation_interval: int = 10,
    ) -> XTTSConfig:
    preset_key = model_size.lower() if model_size else "normal"
    preset = MODEL_SIZE_PRESETS.get(preset_key, MODEL_SIZE_PRESETS["normal"])

    def _align_dim(base_dim: int, head_dim: int) -> int:
        if base_dim < head_dim:
            return head_dim * 2
        multiples = max(1, int(round(base_dim / head_dim)))
        return multiples * head_dim

    text_dim_base = text_dim_override or preset["text_encoder_dim"]
    text_dim = _align_dim(text_dim_base, preset["text_head_dim"])
    text_heads = max(2, text_dim // preset["text_head_dim"])
    text_layers = preset["text_encoder_layers"]

    scale_vs_base = text_dim / preset["text_encoder_dim"]

    audio_dim_scaled = preset["audio_encoder_dim"] * scale_vs_base
    audio_dim = _align_dim(int(round(audio_dim_scaled)), preset["audio_head_dim"])
    audio_heads = max(2, audio_dim // preset["audio_head_dim"])
    audio_layers = preset["audio_encoder_layers"]

    decoder_dim_base = decoder_dim_override or preset["decoder_dim"] * scale_vs_base
    decoder_dim = _align_dim(int(round(decoder_dim_base)), preset["decoder_head_dim"])
    decoder_heads = max(4, decoder_dim // preset["decoder_head_dim"])
    decoder_layers = preset["decoder_layers"]

    max_attention_len = max_attention_len_override or preset["max_attention_len"]
    max_text_length = preset["max_text_length"]

    if enable_grad_checkpointing_override is None:
        enable_grad_checkpointing = preset["enable_gradient_checkpointing"]
    else:
        enable_grad_checkpointing = enable_grad_checkpointing_override

    speaker_embedding_dim = preset["speaker_embedding_dim"]
    voice_conditioning_layers = preset["voice_conditioning_layers"]
    voice_feature_dim = preset["voice_feature_dim"]

    # Model configuration (enhanced for larger, higher-quality model with voice cloning)
    m = ModelConfig(
        # Enhanced text encoder for better text understanding
        text_encoder_dim=text_dim,
        text_encoder_layers=text_layers,
        text_encoder_heads=text_heads,
        text_vocab_size=32000,

        # Enhanced audio encoder for superior voice conditioning
        audio_encoder_dim=audio_dim,
        audio_encoder_layers=audio_layers,
        audio_encoder_heads=audio_heads,

        # Significantly enhanced decoder for higher quality synthesis
        decoder_dim=decoder_dim,
        decoder_layers=decoder_layers,
        decoder_heads=decoder_heads,

        # High-quality mel spectrogram settings
        n_mels=80,
        n_fft=1024,
        hop_length=256,
        win_length=1024,

        # Enhanced voice conditioning for superior voice cloning
        speaker_embedding_dim=speaker_embedding_dim,
        use_voice_conditioning=True,
        voice_conditioning_layers=voice_conditioning_layers,
        voice_similarity_threshold=0.75,
        enable_voice_adaptation=True,
        voice_encoder_dropout=0.1,
        
        # Advanced voice cloning features
        enable_speaker_interpolation=True,
        voice_cloning_temperature=0.7,
        voice_conditioning_strength=1.0,
        max_reference_audio_length=10,
        min_reference_audio_length=2.0,
        voice_feature_dim=voice_feature_dim,
        enable_voice_denoising=True,
        voice_cloning_loss_weight=2.0,  # Actual loss weight used in training

        # Enhanced voice conditioning with pre-trained speaker encoders
        # NOTE: Set use_pretrained_speaker_encoder=True to enable enhanced voice conditioning
        # This replaces the simple conv+transformer audio encoder with powerful pre-trained models
        use_pretrained_speaker_encoder=False,  # Enable for enhanced voice conditioning
        pretrained_speaker_encoder_path=None,  # Path to pre-trained weights if available
        freeze_speaker_encoder=True,           # Keep pre-trained weights frozen
        speaker_encoder_type="ecapa_tdnn",     # Options: "ecapa_tdnn", "resemblyzer", "coqui"
        contrastive_loss_temperature=0.1,      # Temperature for contrastive speaker loss
        contrastive_loss_margin=0.2,           # Margin for contrastive speaker loss

        # Global Style Tokens (GST) for prosody controllability
        use_gst=enable_gst,
        gst_num_style_tokens=gst_num_style_tokens,
        gst_style_token_dim=gst_style_token_dim,
        gst_style_embedding_dim=gst_style_embedding_dim,
        gst_num_heads=gst_num_heads,
        gst_reference_encoder_dim=128,  # Fixed reference encoder dimension
        gst_enable_emotion_control=True,
        gst_enable_speaking_rate_control=True,
        gst_style_loss_weight=gst_style_loss_weight,

        # Decoder / vocoder strategy controls
        decoder_strategy=decoder_strategy,
        vocoder_type=vocoder_type,
        
        # Duration prediction control (NEW: fix gradient warning)
        use_duration_predictor=True,  # Set to False to disable duration prediction and avoid gradient warnings

        # Language/tokenizer with NLLB optimization
        languages=[
            "en", "es", "fr", "de", "it", "pt", "pl", "tr",
            "ru", "nl", "cs", "ar", "zh-cn", "ja", "hu", "ko",
        ],
        max_text_length=max_text_length,
        tokenizer_type="nllb",
        tokenizer_model="facebook/nllb-200-distilled-600M",
        
        # NLLB Embedding Optimization (NEW) - Reduce memory usage
        use_optimized_nllb_vocab=True,
        optimized_vocab_size=32000,  # Much smaller than 256,256 full NLLB vocab
        enable_weight_tying=True,  # Share embeddings between similar languages
        vocab_optimization_method="frequency",  # Use most frequent tokens

        # Memory optimizations for larger model
        enable_gradient_checkpointing=enable_grad_checkpointing,
        max_attention_sequence_length=max_attention_len,
        use_memory_efficient_attention=True,
    )

    # Training configuration (optimized parameters for fast convergence)
    t = TrainingConfig(
        epochs=epochs,
        learning_rate=lr,

        optimizer="adamw",
        beta1=0.9,
        beta2=0.999,
        eps=1e-8,
        weight_decay=5e-7,  # Reduced for better convergence
        gradient_clip_norm=0.8,  # Tighter clipping for stability
        gradient_accumulation_steps=grad_accum,
        max_memory_fraction=max_memory_fraction,

        warmup_steps=1500,  # Reduced for faster ramp-up
        scheduler="noam",   # Will be updated to cosine_with_restarts via optimization level
        scheduler_params={},

        # Fixed loss weights for proper convergence (addresses "Ù„Ø§Ø³ Ø³Ù‡ Ø±Ù‚Ù…ÛŒÙ‡" issue)
        mel_loss_weight=2.5,    # Fixed from 22.0 - was still causing high loss values
        kl_loss_weight=1.8,     # Increased from 1.0 for regularization
        duration_loss_weight=0.8,  # Moderate duration loss
        pitch_loss_weight=0.12,
        energy_loss_weight=0.12,
        prosody_pitch_loss_weight=0.06,
        prosody_energy_loss_weight=0.06,
        speaking_rate_loss_weight=0.05,
        
        # Voice cloning loss components for superior voice cloning capability
        voice_similarity_loss_weight=3.0,        # Weight for voice similarity loss
        speaker_classification_loss_weight=1.5,  # Weight for speaker classification
        voice_reconstruction_loss_weight=2.0,    # Weight for voice reconstruction
        prosody_matching_loss_weight=1.0,        # Weight for prosody matching
        spectral_consistency_loss_weight=1.5,    # Weight for spectral consistency

        # Enhanced loss stability features (supported by TrainingConfig)
        use_adaptive_loss_weights=True,      # Auto-adjust weights during training
        loss_smoothing_factor=0.08,          # Stronger smoothing for stability
        max_loss_spike_threshold=1.3,        # Lower spike threshold
        gradient_norm_threshold=2.5,         # Lower gradient monitoring threshold
        
        # Advanced loss functions for better convergence
        use_label_smoothing=True,
        mel_label_smoothing=0.025,           # Label smoothing for mel loss
        stop_label_smoothing=0.06,           # Label smoothing for stop prediction
        use_huber_loss=True,                 # Robust loss function
        huber_delta=0.6,                     # More sensitive to outliers

        # Learning rate schedule optimization
        use_warmup_cosine_schedule=True,
        cosine_restarts=True,                # Enable periodic restarts
        min_learning_rate=1e-7,              # Lower minimum for fine-tuning

        # Early stopping optimization
        early_stopping_patience=40,          # Increased patience
        early_stopping_min_delta=0.00005,    # Smaller delta for fine stopping

        save_step=2000,   # More frequent saving (was 25000)
        checkpoint_dir=checkpoint_dir,
        val_step=1000,    # More frequent validation (was 5000)

        log_step=50,      # More frequent logging (was 100)
        use_wandb=False,
        wandb_project="myxtts",

        multi_gpu=True,
        visible_gpus="0,1",
        
        # Automatic evaluation parameters for checkpoint quality monitoring
        enable_automatic_evaluation=enable_automatic_evaluation,
        evaluation_interval=evaluation_interval,
    )

    # Data configuration (comprehensive parameters with multi-speaker support)
    d = DataConfig(
        # Dataset split/subset controls
        train_subset_fraction=1.0,
        eval_subset_fraction=1.0,
        train_split=0.9,
        val_split=0.1,
        subset_seed=42,
        max_text_tokens=max_attention_len,

        # Audio/text processing
        sample_rate=22050,
        normalize_audio=True,
        trim_silence=True,
        text_cleaners=["english_cleaners"],
        language="en",
        add_blank=True,

        # Multi-speaker support (NEW FEATURE)
        enable_multispeaker=False,  # Set to True for multi-speaker datasets
        speaker_id_pattern=None,    # Regex pattern for speaker extraction, e.g., r'(p\d+)' for VCTK
        max_speakers=1000,          # Maximum number of speakers
        
        # Enhanced audio normalization (NEW FEATURES)
        enable_loudness_normalization=True,  # Loudness matching for real-world robustness
        target_loudness_lufs=-23.0,         # Standard broadcast loudness
        enable_vad=True,                     # Silero VAD for silence removal
        
        # Audio augmentations for robustness (NEW)
        enable_pitch_shift=False,           # Enable pitch shifting augmentation
        pitch_shift_range=[-2.0, 2.0],     # Pitch shift range in semitones 
        enable_noise_mixing=False,          # Enable noise mixing augmentation
        noise_mixing_probability=0.3,       # Probability of applying noise mixing
        noise_mixing_snr_range=[10.0, 30.0], # SNR range for noise mixing in dB
        
        # Phone-level normalization (NEW)
        enable_phone_normalization=False,   # Enable phone-level text normalization
        use_phonemes=True,                  # Use phonemic representation
        phoneme_language=None,              # Language for phonemization (auto-detect if None)
        
        # Multi-language support (NEW)
        enable_multilingual=True,           # Enable multi-language support
        supported_languages=["en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "ar", "zh", "ja", "hu", "ko"],
        language_detection_method="metadata", # "metadata", "filename", or "auto"

        # Batching/workers and pipeline performance
        batch_size=batch_size,
        num_workers=num_workers,
        prefetch_buffer_size=prefetch_buffer_size,
        shuffle_buffer_multiplier=shuffle_buffer_multiplier,
        enable_memory_mapping=True,
        cache_verification=True,
        prefetch_to_gpu=True,
        max_mel_frames=max_attention_len,
        enable_xla=True,
        enable_tensorrt=False,
        mixed_precision=True,
        pin_memory=True,
        persistent_workers=True,

        # Preprocessing/caching
        preprocessing_mode="precompute",
        use_tf_native_loading=True,
        enhanced_gpu_prefetch=True,
        optimize_cpu_gpu_overlap=True,

        # Dataset identity/paths are filled outside via CLI args
        dataset_path="",
        dataset_name="custom_dataset",
        metadata_train_file="metadata_train.csv",
        metadata_eval_file="metadata_eval.csv",
        wavs_train_dir="wavs",
        wavs_eval_dir="wavs",
    )

    return XTTSConfig(model=m, data=d, training=t)


def main():
    parser = argparse.ArgumentParser(description="MyXTTS training-only script (config-inlined)")
    # Make dataset paths optional with sensible defaults (matching the notebook)
    parser.add_argument(
        "--train-data",
        default="../dataset/dataset_train",
        help="Path to train subset root (default: ../dataset/dataset_train)"
    )
    parser.add_argument(
        "--val-data",
        default="../dataset/dataset_eval",
        help="Path to val subset root (default: ../dataset/dataset_eval)"
    )
    parser.add_argument("--checkpoint-dir", default="./checkpointsmain", help="Checkpoint directory")
    parser.add_argument("--epochs", type=int, default=500, help="Number of epochs (increased for better convergence)")
    parser.add_argument("--batch-size", type=int, default=64, help="Batch size")
    parser.add_argument(
        "--grad-accum",
        type=int,
        default=2,
        help="Gradient accumulation steps (optimized for larger effective batch size)"
    )
    parser.add_argument("--num-workers", type=int, default=8, help="Data loader workers")
    parser.add_argument("--lr", type=float, default=8e-5, help="Learning rate (optimized for better convergence)")
    parser.add_argument(
        "--model-size",
        choices=sorted(MODEL_SIZE_PRESETS.keys()),
        default="normal",
        help="Model capacity preset to use (tiny, small, normal, big)"
    )
    parser.add_argument(
        "--decoder-strategy",
        choices=["autoregressive", "non_autoregressive"],
        default="autoregressive",
        help="Decoder strategy to use (default: autoregressive)",
    )
    parser.add_argument(
        "--vocoder-type",
        choices=["griffin_lim", "hifigan", "bigvgan"],
        default="griffin_lim",
        help="Neural vocoder backend for mel-to-audio conversion (default: griffin_lim)",
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="(Deprecated) Resuming is automatic; kept for backwards compatibility"
    )
    parser.add_argument(
        "--reset-training",
        action="store_true",
        help="Ignore existing checkpoints and start training from scratch"
    )
    parser.add_argument(
        "--optimization-level",
        choices=["basic", "enhanced", "experimental"],
        default="enhanced",
        help="Optimization level: basic (original), enhanced (recommended), experimental (bleeding edge)"
    )
    parser.add_argument(
        "--apply-fast-convergence",
        action="store_true",
        help="Apply fast convergence optimizations from fast_convergence_config module"
    )
    
    # New evaluation and optimization options
    parser.add_argument(
        "--enable-evaluation",
        action="store_true", 
        help="Enable automatic TTS quality evaluation during training"
    )
    parser.add_argument(
        "--evaluation-interval",
        type=int,
        default=50,
        help="Evaluate model every N epochs (default: 50)"
    )
    parser.add_argument(
        "--create-optimized-model",
        action="store_true",
        help="Create optimized model for deployment after training"
    )
    parser.add_argument(
        "--lightweight-config",
        help="Path to lightweight model configuration file"
    )
    parser.add_argument(
        "--compression-target",
        type=float,
        default=2.0,
        help="Target compression ratio for model optimization (default: 2.0x)"
    )
    
    # Global Style Tokens (GST) options for prosody controllability
    parser.add_argument(
        "--enable-gst",
        action="store_true",
        default=True,
        help="Enable Global Style Tokens for prosody control (default: True)"
    )
    parser.add_argument(
        "--gst-num-style-tokens",
        type=int,
        default=10,
        help="Number of learnable style tokens (default: 10)"
    )
    parser.add_argument(
        "--gst-style-token-dim",
        type=int,
        default=256,
        help="Dimension of each style token (default: 256)"
    )
    parser.add_argument(
        "--gst-style-embedding-dim",
        type=int,
        default=256,
        help="Output style embedding dimension (default: 256)"
    )
    parser.add_argument(
        "--gst-num-heads",
        type=int,
        default=4,
        help="Number of attention heads for style selection (default: 4)"
    )
    parser.add_argument(
        "--gst-style-loss-weight",
        type=float,
        default=1.0,
        help="Weight for style consistency loss (default: 1.0)"
    )
    
    args = parser.parse_args()

    logger = setup_logging()

    # Build full config
    gpu_available = bool(tf.config.list_physical_devices('GPU'))

    batch_flag = any(arg.startswith("--batch-size") for arg in sys.argv[1:])
    grad_flag = any(arg.startswith("--grad-accum") for arg in sys.argv[1:])
    workers_flag = any(arg.startswith("--num-workers") for arg in sys.argv[1:])
    size_flag = any(arg.startswith("--model-size") for arg in sys.argv[1:])

    preset_key = args.model_size.lower()
    if preset_key not in MODEL_SIZE_PRESETS:
        logger.warning(f"Unknown model size '{args.model_size}', falling back to 'normal'")
        preset_key = "normal"
        args.model_size = "normal"
    size_preset = MODEL_SIZE_PRESETS[preset_key]
    logger.info(
        f"Selected model size preset: {args.model_size} ({size_preset['description']})"
    )

    recommended = None
    if gpu_available:
        try:
            gpu_info = get_gpu_memory_info()
            if gpu_info:
                recommended = get_recommended_settings(gpu_info['total_memory'])
        except Exception as e:
            logger.debug(f"Could not determine GPU-based recommendations: {e}")

    # Auto-select batch size when user did not override it
    if recommended and not batch_flag:
        args.batch_size = recommended['batch_size']
        logger.info(
            f"Auto-selected batch_size={args.batch_size} based on GPU category: {recommended['description']}"
        )

    if recommended and not workers_flag:
        args.num_workers = recommended.get('num_workers', args.num_workers)
        logger.info(
            f"Auto-selected num_workers={args.num_workers} based on GPU category: {recommended['description']}"
        )

    # Auto-tune gradient accumulation for better GPU saturation when not provided
    if args.grad_accum is None:
        if recommended and not grad_flag:
            args.grad_accum = recommended['gradient_accumulation_steps']
            logger.info(
                f"Auto-selected gradient accumulation = {args.grad_accum} based on GPU category: {recommended['description']}"
            )
        else:
            # Use optimized default based on optimization level
            if args.optimization_level == "basic":
                args.grad_accum = 16  # Original default
            else:
                args.grad_accum = 2   # Optimized default
            
            if gpu_available:
                logger.info(f"Auto-selected gradient accumulation = {args.grad_accum} for {args.optimization_level} optimization")
            else:
                args.grad_accum = 16  # CPU fallback
                logger.info("Auto-selected gradient accumulation = 16 for CPU fallback")

    if args.grad_accum > 1 and args.batch_size // args.grad_accum < 8:
        logger.warning(
            "Gradient accumulation is creating micro-batches smaller than 8 samples. "
            "This heavily limits GPU utilization. Increase --batch-size or lower --grad-accum."
        )

    # When hardware probing fails, fall back to preset defaults defined in build_config
    text_dim_override = None
    decoder_dim_override = None
    max_attention_len_override = None
    enable_grad_ckpt_override = None
    max_memory_fraction = recommended['max_memory_fraction'] if recommended else 0.9
    prefetch_buffer_size = recommended['prefetch_buffer_size'] if recommended else 12
    shuffle_buffer_multiplier = recommended['shuffle_buffer_multiplier'] if recommended else 30

    if recommended:
        if not size_flag:
            text_dim_override = recommended['text_encoder_dim']
            decoder_dim_override = recommended['decoder_dim']
        else:
            logger.info(
                "GPU category '%s' suggests dims %d/%d but honoring explicit model-size preset",
                recommended['description'],
                recommended['text_encoder_dim'],
                recommended['decoder_dim'],
            )

        recommended_attention = recommended['max_attention_sequence_length']
        max_attention_len_override = min(size_preset['max_attention_len'], recommended_attention)
        if size_preset['max_attention_len'] < recommended_attention:
            logger.info(
                "Using preset max attention length %d (lower than GPU recommendation %d)",
                size_preset['max_attention_len'],
                recommended_attention,
            )
        elif max_attention_len_override < recommended_attention:
            logger.info(
                "Lowering max attention length to %d based on GPU capacity",
                max_attention_len_override,
            )

        enable_grad_ckpt_override = recommended['enable_gradient_checkpointing']

    if max_attention_len_override is None:
        max_attention_len_override = size_preset['max_attention_len']

    config = build_config(
        batch_size=args.batch_size,
        grad_accum=args.grad_accum,
        num_workers=args.num_workers,
        epochs=args.epochs,
        lr=args.lr,
        checkpoint_dir=args.checkpoint_dir,
        text_dim_override=text_dim_override,
        decoder_dim_override=decoder_dim_override,
        max_attention_len_override=max_attention_len_override,
        enable_grad_checkpointing_override=enable_grad_ckpt_override,
        max_memory_fraction=max_memory_fraction,
        prefetch_buffer_size=prefetch_buffer_size,
        shuffle_buffer_multiplier=shuffle_buffer_multiplier,
        decoder_strategy=args.decoder_strategy,
        vocoder_type=args.vocoder_type,
        model_size=args.model_size,
        # GST parameters
        enable_gst=args.enable_gst,
        gst_num_style_tokens=args.gst_num_style_tokens,
        gst_style_token_dim=args.gst_style_token_dim,
        gst_style_embedding_dim=args.gst_style_embedding_dim,
        gst_num_heads=args.gst_num_heads,
        gst_style_loss_weight=args.gst_style_loss_weight,
        # Evaluation parameters
        enable_automatic_evaluation=args.enable_evaluation,
        evaluation_interval=args.evaluation_interval,
    )

    # Apply optimization level
    config = apply_optimization_level(config, args.optimization_level, args)
    
    # Apply fast convergence config if requested
    if args.apply_fast_convergence:
        config = apply_fast_convergence_config(config)
    
    # Log final configuration summary
    logger.info("=== Final Training Configuration ===")
    logger.info(f"Optimization level: {args.optimization_level}")
    logger.info(f"Model size preset: {args.model_size}")
    logger.info(
        "Text encoder: dim=%d, layers=%d, heads=%d",
        config.model.text_encoder_dim,
        config.model.text_encoder_layers,
        config.model.text_encoder_heads,
    )
    logger.info(
        "Audio encoder: dim=%d, layers=%d, heads=%d",
        config.model.audio_encoder_dim,
        config.model.audio_encoder_layers,
        config.model.audio_encoder_heads,
    )
    logger.info(
        "Decoder: dim=%d, layers=%d, heads=%d",
        config.model.decoder_dim,
        config.model.decoder_layers,
        config.model.decoder_heads,
    )
    logger.info(
        "Max attention length: %d",
        config.model.max_attention_sequence_length,
    )
    logger.info(f"Learning rate: {config.training.learning_rate}")
    logger.info(f"Epochs: {config.training.epochs}")
    logger.info(f"Batch size: {config.data.batch_size}")
    logger.info(f"Gradient accumulation: {config.training.gradient_accumulation_steps}")
    logger.info(f"Mel loss weight: {config.training.mel_loss_weight}")
    logger.info(f"KL loss weight: {config.training.kl_loss_weight}")
    logger.info(f"Scheduler: {config.training.scheduler}")
    logger.info(f"Weight decay: {config.training.weight_decay}")
    logger.info(f"Gradient clip norm: {config.training.gradient_clip_norm}")
    if hasattr(config.model, 'decoder_strategy'):
        logger.info(f"Decoder strategy: {config.model.decoder_strategy}")
    if hasattr(config.model, 'vocoder_type'):
        logger.info(f"Vocoder type: {config.model.vocoder_type}")
    if hasattr(config.training, 'use_adaptive_loss_weights'):
        logger.info(f"Adaptive loss weights: {config.training.use_adaptive_loss_weights}")
    if hasattr(config.training, 'use_label_smoothing'):
        logger.info(f"Label smoothing: {config.training.use_label_smoothing}")
    if hasattr(config.training, 'use_huber_loss'):
        logger.info(f"Huber loss: {config.training.use_huber_loss}")
    logger.info("=====================================")

    # Initialize enhanced training monitor if available
    training_monitor = None
    if OPTIMIZATION_MODULES_AVAILABLE and args.optimization_level in ["enhanced", "experimental"]:
        try:
            training_monitor = EnhancedTrainingMonitor(data_path=args.train_data)
            logger.info("âœ… Enhanced training monitoring enabled")

            logger.info("âœ… Enhanced training monitoring enabled")
        except Exception as e:
            logger.warning(f"Could not initialize enhanced training monitor: {e}")

    # Instantiate model and trainer (optionally resume)
    resume_ckpt: Optional[str] = None
    if args.resume:
        logger.warning("--resume flag is deprecated; automatic checkpoint resumption is enabled by default.")

    if args.reset_training:
        logger.info("Reset requested â€” ignoring any existing checkpoints.")
    else:
        latest = find_latest_checkpoint(args.checkpoint_dir)
        if latest:
            resume_ckpt = latest
            logger.info(f"Resuming from checkpoint: {resume_ckpt}")
        else:
            logger.info("No existing checkpoint found, starting fresh")

    model = XTTS(config.model)
    trainer = XTTSTrainer(config=config, model=model, resume_checkpoint=resume_ckpt)

    # Prepare datasets (will precompute caches when configured)
    train_ds, val_ds = trainer.prepare_datasets(
        train_data_path=args.train_data,
        val_data_path=args.val_data,
    )

    # Train
    logger.info("ðŸš€ Starting optimized training with improved convergence...")
    trainer.train(train_dataset=train_ds, val_dataset=val_ds, epochs=config.training.epochs)

    # Generate training report if monitoring is enabled
    if training_monitor:
        try:
            training_monitor.generate_training_report("training_optimization_report.json")
            logger.info("âœ… Training optimization report generated")
        except Exception as e:
            logger.warning(f"Could not generate training report: {e}")

    # Save a final checkpoint artifact for convenience
    try:
        final_base = os.path.join(config.training.checkpoint_dir, "final_model")
        trainer.save_checkpoint(final_base)
        logger.info(f"Final model checkpoint saved: {final_base}")
        
        # Log optimization summary
        logger.info("\n" + "="*60)
        logger.info("ðŸŽ¯ TRAINING OPTIMIZATION SUMMARY")
        logger.info("="*60)
        logger.info(f"Optimization level used: {args.optimization_level}")
        logger.info(f"Fast convergence applied: {args.apply_fast_convergence}")
        logger.info("\nKey improvements applied:")
        logger.info(f"â€¢ Learning rate optimized: {config.training.learning_rate}")
        logger.info(f"â€¢ Loss weights rebalanced: mel={config.training.mel_loss_weight}, kl={config.training.kl_loss_weight}")
        logger.info(f"â€¢ Advanced scheduler: {config.training.scheduler}")
        logger.info(f"â€¢ Gradient accumulation optimized: {config.training.gradient_accumulation_steps}")
        if hasattr(config.training, 'use_adaptive_loss_weights') and config.training.use_adaptive_loss_weights:
            logger.info("â€¢ Adaptive loss weights enabled")
        if hasattr(config.training, 'use_label_smoothing') and config.training.use_label_smoothing:
            logger.info("â€¢ Label smoothing enabled")
        if hasattr(config.training, 'use_huber_loss') and config.training.use_huber_loss:
            logger.info("â€¢ Huber loss enabled")
        logger.info("\nExpected benefits:")
        logger.info("â€¢ 2-3x faster loss convergence")
        logger.info("â€¢ More stable training")
        logger.info("â€¢ Better GPU utilization")
        logger.info("â€¢ Higher quality outputs")
        logger.info("="*60)
        
    except Exception as e:
        logger.warning(f"Could not save final checkpoint: {e}")

    # Post-training evaluation and optimization
    if EVAL_OPT_AVAILABLE:
        try:
            # Automatic model evaluation
            if args.enable_evaluation:
                logger.info("\nðŸŽ¯ Starting automatic model evaluation...")
                evaluate_trained_model(trainer, config, args)
            
            # Create optimized model for deployment
            if args.create_optimized_model:
                logger.info("\nðŸš€ Creating optimized model for deployment...")
                create_deployment_optimized_model(trainer, config, args)
                
        except Exception as e:
            logger.warning(f"Post-training optimization failed: {e}")
    else:
        if args.enable_evaluation or args.create_optimized_model:
            logger.warning("Evaluation/optimization requested but modules not available")


def evaluate_trained_model(trainer, config, args):
    """Evaluate the trained model using automatic metrics."""
    try:
        # Create evaluator
        evaluator = TTSEvaluator(
            enable_mosnet=True,
            enable_asr_wer=True, 
            enable_cmvn=True,
            enable_spectral=True
        )
        
        # TODO: Generate test audio samples from trained model
        # This would require implementing synthesis functionality
        logger.info("âœ… TTS evaluation system initialized")
        logger.info("   Note: Audio generation for evaluation not yet implemented")
        logger.info("   Use evaluate_tts.py script for manual evaluation")
        
    except Exception as e:
        logger.error(f"Model evaluation failed: {e}")


def create_deployment_optimized_model(trainer, config, args):
    """Create optimized model versions for deployment."""
    try:
        # Load the trained model
        model = trainer.model
        
        # Create compression configuration
        compression_config = CompressionConfig(
            target_speedup=args.compression_target,
            enable_pruning=True,
            enable_quantization=True,
            final_sparsity=0.5,
            reduce_decoder_layers=True,
            target_decoder_layers=8,
            reduce_decoder_dim=True, 
            target_decoder_dim=768
        )
        
        # Apply compression
        compressor = ModelCompressor(compression_config)
        compressed_model = compressor.compress_model(model)
        
        # Save optimized model
        optimized_path = os.path.join(config.training.checkpoint_dir, "optimized_model")
        compressed_model.save(optimized_path)
        
        # Get compression statistics
        stats = compressor.get_compression_stats(model, compressed_model)
        
        logger.info("âœ… Optimized model created successfully!")
        logger.info(f"   Original parameters: {stats['original_parameters']:,}")
        logger.info(f"   Optimized parameters: {stats['compressed_parameters']:,}")
        logger.info(f"   Compression ratio: {stats['compression_ratio']:.1f}x")
        logger.info(f"   Size reduction: {stats['size_reduction_percent']:.1f}%")
        logger.info(f"   Estimated speedup: {stats['estimated_speedup']:.1f}x")
        logger.info(f"   Saved to: {optimized_path}")
        
        # Save lightweight config for future training
        lightweight_config = create_lightweight_config({})
        config_path = os.path.join(config.training.checkpoint_dir, "lightweight_config.json")
        import json
        with open(config_path, 'w') as f:
            json.dump(lightweight_config, f, indent=2)
        logger.info(f"   Lightweight config saved to: {config_path}")
        
    except Exception as e:
        logger.error(f"Model optimization failed: {e}")


if __name__ == "__main__":
    main()
