# üéØ Static Shapes CLI Guide

## Overview

This guide explains how to use the new `--enable-static-shapes` CLI argument to prevent tf.function retracing and stabilize GPU utilization during training.

## The Problem

Without static shapes enabled:
- ‚ùå GPU utilization oscillates between 2-40%
- ‚ùå tf.function retracing every 5-6 batches
- ‚ùå 27-30 second delays during retracing
- ‚ùå Extremely slow and unstable training

With static shapes enabled:
- ‚úÖ GPU utilization stable at 70-90%
- ‚úÖ Zero retracing after initial compilation
- ‚úÖ Training step time: ~0.5s (down from 15-30s average)
- ‚úÖ Fast and stable training

## Quick Start

### Basic Usage

```bash
# Enable static shapes with default settings
python3 train_main.py --enable-static-shapes --batch-size 16

# Alternative flag name (same effect)
python3 train_main.py --pad-to-fixed-length --batch-size 16
```

### Advanced Usage

```bash
# Customize padding lengths for your dataset
python3 train_main.py --enable-static-shapes \
    --max-text-length 200 \
    --max-mel-frames 800 \
    --batch-size 16

# For tiny model with limited GPU memory
python3 train_main.py --model-size tiny \
    --enable-static-shapes \
    --batch-size 8 \
    --max-text-length 150 \
    --max-mel-frames 600

# Full optimization (recommended for production)
python3 train_main.py --enable-static-shapes \
    --optimization-level enhanced \
    --batch-size 16 \
    --max-text-length 200 \
    --max-mel-frames 800
```

## CLI Arguments

### `--enable-static-shapes` (or `--pad-to-fixed-length`)

Enables fixed-length padding to prevent tf.function retracing.

- **Type**: Boolean flag (no value needed)
- **Default**: `False` (disabled)
- **Recommended**: `True` for stable GPU utilization

**Example:**
```bash
python3 train_main.py --enable-static-shapes
```

### `--max-text-length <int>`

Sets the maximum text sequence length for fixed padding.

- **Type**: Integer
- **Default**: `200`
- **Recommended**: Choose based on your dataset's longest text

**How to choose:**
1. Check your dataset's maximum text length
2. Add 10-20% buffer for safety
3. Round up to a nice number (e.g., 150, 200, 250)

**Example:**
```bash
python3 train_main.py --enable-static-shapes --max-text-length 180
```

### `--max-mel-frames <int>`

Sets the maximum mel spectrogram frames for fixed padding.

- **Type**: Integer
- **Default**: Auto-calculated from model config (usually 1024)
- **Recommended**: Choose based on your dataset's longest audio

**How to choose:**
1. Calculate: `(max_audio_seconds * sample_rate) / hop_length`
2. For 22kHz audio with hop_length=256:
   - 5 seconds ‚Üí ~430 frames
   - 10 seconds ‚Üí ~860 frames
   - 15 seconds ‚Üí ~1290 frames
3. Add buffer and round up

**Example:**
```bash
python3 train_main.py --enable-static-shapes --max-mel-frames 800
```

## What Happens When Enabled

### 1. Configuration

When you run:
```bash
python3 train_main.py --enable-static-shapes --batch-size 16
```

The training script will:
1. Parse CLI arguments
2. Set `config.data.pad_to_fixed_length = True`
3. Set `config.data.max_text_length = 200` (or your custom value)
4. Set `config.data.max_mel_frames` from model config (or your custom value)

### 2. Data Pipeline

The data loader will:
1. Pad all text sequences to exactly `max_text_length`
2. Pad all mel spectrograms to exactly `max_mel_frames`
3. All batches will have identical shapes: `[batch_size, max_text_length]` and `[batch_size, max_mel_frames, n_mels]`

### 3. Training Loop

The trainer will:
1. Use static shapes (`.shape`) instead of dynamic shapes (`tf.shape()`)
2. Compile the training step once during first batch
3. Reuse the compiled function for all subsequent batches
4. No retracing warnings

### 4. GPU Utilization

Your GPU will:
1. Run at stable 70-90% utilization
2. Process batches ~30x faster (0.5s vs 15-30s)
3. Complete training much faster

## Verification

### Check Configuration

The training script will log the configuration at startup:

```
=== Final Training Configuration ===
...
Static shapes (pad_to_fixed_length): True
  ‚úÖ ENABLED - This prevents tf.function retracing and stabilizes GPU utilization
  Max text length: 200
  Max mel frames: 800
...
```

### Monitor Training

During training, you should see:
- Initial compilation (first batch): ~5-10 seconds
- Subsequent batches: ~0.5 seconds each
- No retracing warnings
- Stable GPU utilization (use `nvidia-smi` to monitor)

### Warning Signs

If you see these warnings, static shapes may not be working:
```
WARNING: Retracing! This will slow down training significantly.
‚ùå CAUSE: pad_to_fixed_length is disabled in config!
```

**Solution:** Make sure you're using the `--enable-static-shapes` flag.

## Troubleshooting

### Out of Memory (OOM) Errors

If you get OOM errors after enabling static shapes:

1. **Reduce batch size:**
   ```bash
   python3 train_main.py --enable-static-shapes --batch-size 8
   ```

2. **Reduce padding lengths:**
   ```bash
   python3 train_main.py --enable-static-shapes \
       --max-text-length 150 \
       --max-mel-frames 600
   ```

3. **Use tiny model:**
   ```bash
   python3 train_main.py --model-size tiny \
       --enable-static-shapes \
       --batch-size 8
   ```

### Slow Training Despite Static Shapes

If training is still slow:

1. **Verify static shapes are enabled:**
   - Check the configuration log at startup
   - Look for "Static shapes (pad_to_fixed_length): True"

2. **Check for other bottlenecks:**
   ```bash
   # Run diagnostic tool
   python utilities/diagnose_retracing.py --config configs/config.yaml
   ```

3. **Ensure data pipeline is optimized:**
   - Check `num_workers` is appropriate (usually 8-16)
   - Check `prefetch_buffer_size` is set (usually 8-12)

### Validation Errors

If you get validation errors about sequence lengths:

Your dataset may have sequences longer than `max_text_length` or `max_mel_frames`.

**Solution:** Increase the padding lengths:
```bash
python3 train_main.py --enable-static-shapes \
    --max-text-length 250 \
    --max-mel-frames 1000
```

## Best Practices

1. **Always use static shapes for production training:**
   ```bash
   python3 train_main.py --enable-static-shapes --optimization-level enhanced
   ```

2. **Choose padding lengths based on your dataset:**
   - Analyze your dataset first
   - Add 10-20% buffer
   - Don't over-pad (wastes memory)

3. **Monitor GPU utilization:**
   ```bash
   watch -n 1 nvidia-smi
   ```
   - Should be stable at 70-90%
   - If oscillating, check configuration

4. **Start with defaults, then optimize:**
   ```bash
   # Start with defaults
   python3 train_main.py --enable-static-shapes
   
   # Monitor and adjust if needed
   python3 train_main.py --enable-static-shapes --max-text-length 180
   ```

## Examples

### Example 1: Quick Test

```bash
# Quick test with small model
python3 train_main.py --model-size tiny \
    --enable-static-shapes \
    --batch-size 8 \
    --epochs 10
```

### Example 2: Production Training

```bash
# Full production training
python3 train_main.py --enable-static-shapes \
    --optimization-level enhanced \
    --batch-size 16 \
    --epochs 500 \
    --max-text-length 200 \
    --max-mel-frames 800 \
    --train-data ../dataset/dataset_train \
    --val-data ../dataset/dataset_eval
```

### Example 3: Large Dataset

```bash
# For datasets with longer sequences
python3 train_main.py --enable-static-shapes \
    --optimization-level enhanced \
    --batch-size 12 \
    --max-text-length 300 \
    --max-mel-frames 1200
```

### Example 4: Limited GPU Memory

```bash
# For GPUs with limited memory (e.g., 8GB)
python3 train_main.py --model-size tiny \
    --enable-static-shapes \
    --batch-size 4 \
    --max-text-length 150 \
    --max-mel-frames 600
```

## Related Documentation

- [`RETRACING_COMPLETE_SOLUTION.md`](RETRACING_COMPLETE_SOLUTION.md) - Complete technical explanation
- [`README.md`](README.md) - General project documentation
- [`tests/test_static_shapes_cli.py`](tests/test_static_shapes_cli.py) - CLI validation tests

## FAQ

### Q: Do I need to edit config files?

A: No! The CLI flags automatically configure everything. Config files are optional.

### Q: Can I use both CLI flags and config files?

A: Yes! CLI flags override config file settings.

### Q: What if I don't know my dataset's max lengths?

A: Start with defaults (200 for text, 800-1024 for mel). The script will work but may waste some memory.

### Q: Will this work with multi-GPU training?

A: Currently, this is designed for single-GPU training. Multi-GPU support is not implemented.

### Q: How much faster will training be?

A: Typically 20-30x faster. Training step time goes from 15-30s to ~0.5s.

### Q: Can I disable static shapes?

A: Yes, just don't use the `--enable-static-shapes` flag. However, this is not recommended as it leads to unstable GPU utilization.

## Conclusion

The `--enable-static-shapes` CLI flag is the recommended way to train MyXTTS models with stable GPU utilization. It's easy to use, requires no config file editing, and dramatically improves training speed.

**Bottom line:** Always use `--enable-static-shapes` for production training.
