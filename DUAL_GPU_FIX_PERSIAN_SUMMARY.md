# ุฎูุงุตู ุฑุงูฺฉุงุฑ ุฑูุน Bottleneck ุฏุฑ Dual-GPU Pipeline
# Dual-GPU Pipeline Bottleneck Fix - Persian Summary

## ๐ฏ ุฎูุงุตู ูุดฺฉู

ุฏุฑ ุญุงูุช dual-GPU ุจุง memory isolationุ ูุฑ ุฏู GPU ูุนุงู ุจูุฏูุฏ ุงูุง:
- GPU utilization ฺฉูุชุฑ ุงุฒ 70% ุจูุฏ
- ุณุฑุนุช training ูุงูพุงุฏุงุฑ ู oscillating ุจูุฏ
- ุจุง batch-size 32 ุฎุทุง OOM ูโุฏุงุฏ
- ุนููฺฉุฑุฏ ุฎู ฺฉูุชุฑ ุงุฒ ุงูุชุธุงุฑ ุจูุฏ

## โ ุฑุงูฺฉุงุฑ ูพุงุฏูโุณุงุฒ ุดุฏู

### 1. ูุนูุงุฑ Pipeline ุบุฑููุฒูุงู (Async)

**ูุจู:**
```
ูุฑุญูู N:   [ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏู] โ [ูพุฑุฏุงุฒุด] โ [ุงูุชูุงู] โ [ุขููุฒุด]
ูุฑุญูู N+1:                                             [ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏู] โ ...

GPU:0 ููุชุธุฑ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโบ
                                           GPU:1 ููุชุธุฑ โโโโโโโโโโโโโโโโโบ
```

**ุจุนุฏ (ุจููู ุดุฏู):**
```
ูุฑุญูู N:   [ุจุงุฑฺฏุฐุงุฑ] โ [ูพุฑุฏุงุฒุด] โ [ุงูุชูุงู] โ
ูุฑุญูู N+1:                        [ุจุงุฑฺฏุฐุงุฑ]โโผโโบ [ุขููุฒุด N]
ูุฑุญูู N+2:                                    โโโบ [ูพุฑุฏุงุฒุด N+1] โ [ุขููุฒุด N+1]

GPU:0 ูุดุบูู โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโบ
                                           GPU:1 ูุดุบูู โโโโโโโโโโโโโโโโโบ
```

### 2. ุจูููโุณุงุฒโูุง ฺฉูุฏ

#### ุงูู) Triple Buffering
- ูุจู: 2 ุจุงูุฑ (ฺฉุงู ูุจูุฏ)
- ุจุนุฏ: 3 ุจุงูุฑ (pipeline ุฑูุงูโุชุฑ)
- ูุชุฌู: ฺฉูุชุฑ ููุชุธุฑ ูุงูุฏูุ overlap ุจุดุชุฑ

#### ุจ) Async Transfer
- ุงูุชูุงู ุฏุงุฏู ุจู GPUูุง ุบุฑููฺฏุงู
- GPU:0 ูโุชูุงูุฏ ุจูุงูุงุตูู batch ุจุนุฏ ุฑุง ุขูุงุฏู ฺฉูุฏ
- ุงุณุชูุงุฏู ุงุฒ DMA hardware ุจุฑุง ุงูุชูุงู ุณุฑุน

#### ุฌ) ุจูููโุณุงุฒ Dataset
- Prefetch ูุณุชูู ุจู GPU:0
- Parallel processing ูุนุงู
- Auto-tuning ุจุฑุง ุชูุธู ุฎูุฏฺฉุงุฑ

#### ุฏ) Performance Monitoring
- ุซุจุช ุฒูุงู ูุฑ step
- ุชุดุฎุต variation ุจุงูุง (ูุดุงูู bottleneck)
- ฺฏุฒุงุฑุด ุฎูุฏฺฉุงุฑ ูุดฺฉูุงุช

## ๐ ูุชุงุฌ ููุฑุฏ ุงูุชุธุงุฑ

| ูุนุงุฑ | ูุจู | ุจุนุฏ | ุจูุจูุฏ |
|-------|-----|-----|-------|
| ุงุณุชูุงุฏู GPU:0 | 20-40% | 40-60% | 2 ุจุฑุงุจุฑ |
| ุงุณุชูุงุฏู GPU:1 | 50-70% | 80-95% | 1.5 ุจุฑุงุจุฑ |
| ุซุจุงุช ุฒูุงู | 50-80% ุชุบุฑ | 15-30% ุชุบุฑ | 3 ุจุฑุงุจุฑ ุจูุชุฑ |
| ุณุฑุนุช | 3-4 step/s | 6-8 step/s | 2 ุจุฑุงุจุฑ ุณุฑุนุชุฑ |

## ๐ ูุญูู ุงุณุชูุงุฏู

### ฺฏุงู 1: ุชุดุฎุต ูุถุนุช ูุนู

```bash
python utilities/dual_gpu_bottleneck_profiler.py \
  --batch-size 16 \
  --num-steps 100 \
  --data-gpu 0 \
  --model-gpu 1
```

ุงู ุงุจุฒุงุฑ ุจู ุดูุง ูโฺฏูุฏ:
- ฺฉุฌุง bottleneck ุงุณุช
- GPU utilization ูุงูุน ฺูุฏุฑ ุงุณุช
- ฺู ุชูุธูุงุช ูุงุฒู ุงุณุช

### ฺฏุงู 2: ุขููุฒุด ุจุง ุชูุธูุงุช ุจููู

**ุจุฑุง RTX 4090 ุง ูุดุงุจู (24GB):**
```bash
python train_main.py \
  --model-size tiny \
  --batch-size 16 \
  --data-gpu 0 \
  --model-gpu 1 \
  --enable-memory-isolation \
  --enable-static-shapes \
  --data-gpu-memory 8192 \
  --model-gpu-memory 16384 \
  --train-data ./data/dataset_train
```

**ุจุฑุง GPUูุง ฺฉูฺฺฉโุชุฑ (12-16GB):**
```bash
python train_main.py \
  --model-size tiny \
  --batch-size 8 \
  --data-gpu 0 \
  --model-gpu 1 \
  --enable-memory-isolation \
  --data-gpu-memory 4096 \
  --model-gpu-memory 8192 \
  --train-data ./data/dataset_train
```

### ฺฏุงู 3: ูุธุงุฑุช

```bash
watch -n 1 nvidia-smi
```

**ุจุงุฏ ุจุจูุฏ:**
- GPU 0: 40-60% ุงุณุชูุงุฏู (ูพุฑุฏุงุฒุด ุฏุงุฏู)
- GPU 1: 80-95% ุงุณุชูุงุฏู (ุขููุฒุด ูุฏู)
- ุญุงูุธู ูพุงุฏุงุฑ (ุฑุดุฏ ูฺฉูุฏ)
- ูุตุฑู ุจุฑู ุจุงูุง ุฏุฑ ูุฑ ุฏู GPU

## ๐ง ุญู ูุดฺฉูุงุช ุฑุงุฌ

### ูุดฺฉู 1: ุงุณุชูุงุฏู GPU ูููุฒ ูพุงู ุงุณุช (<70%)

**ุนูุช ุงุญุชูุงู:** ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏู ฺฉูุฏ ุงุณุช

**ุฑุงูฺฉุงุฑ:**
```yaml
# ุฏุฑ ูุงู configs/config.yaml
data:
  num_workers: 24              # ุงูุฒุงุด ุงุฒ 16 ุจู 24
  prefetch_buffer_size: 6      # ุงูุฒุงุด ุงุฒ 4 ุจู 6
  use_tf_native_loading: true  # ุญุชูุงู ูุนุงู ุจุงุดุฏ
```

### ูุดฺฉู 2: OOM ุจุง batch-size ุจุฒุฑฺฏุชุฑ

**ุฑุงูฺฉุงุฑ 1:** ุงูุฒุงุด ุญุฏ ุญุงูุธู
```bash
--data-gpu-memory 10240 \
--model-gpu-memory 20480
```

**ุฑุงูฺฉุงุฑ 2:** ฺฉุงูุด batch size
```bash
--batch-size 16  # ุจู ุฌุง 32
```

**ุฑุงูฺฉุงุฑ 3:** ฺฉุงูุด prefetch buffer
```bash
--prefetch-buffer-size 2  # ุจู ุฌุง 4
```

### ูุดฺฉู 3: ุชุบุฑุงุช ุฒูุงู ุฒุงุฏ (>30%)

**ุฑุงูฺฉุงุฑ:**
```bash
# ุงูุฒุงุด buffer ู workers
python train_main.py \
  ... \
  --prefetch-buffer-size 8
```

ู ุฏุฑ config:
```yaml
data:
  num_workers: 24  # ุงุฒ 16 ุจุดุชุฑ
```

## ๐ ุฌุฏูู ูพฺฉุฑุจูุฏ ูพุดููุงุฏ

| ุญุงูุธู GPU | Batch Size | data-gpu-memory | model-gpu-memory | Prefetch |
|-----------|------------|-----------------|------------------|----------|
| 12GB ูุฑฺฉุฏุงู | 8 | 4096 | 8192 | 6-8 |
| 16GB ูุฑฺฉุฏุงู | 12 | 6144 | 10240 | 4-6 |
| 24GB ูุฑฺฉุฏุงู | 16-24 | 8192 | 16384 | 2-4 |

## ๐ก ูฺฉุงุช ููู

### ฺู ฺุฒูุง ุชุบุฑ ฺฉุฑุฏุ

1. **ุณุงุฎุชุงุฑ Pipeline:**
   - ุงุฒ ุญุงูุช ุชุฑุชุจ ุจู ููุงุฒ ุชุจุฏู ุดุฏ
   - GPU:0 ู GPU:1 ููุฒูุงู ฺฉุงุฑ ูโฺฉููุฏ
   - ฺฉูุชุฑ ููุชุธุฑ ูโูุงููุฏ

2. **ุณุณุชู Buffer:**
   - ุงุฒ 2 ุจุงูุฑ ุจู 3 ุจุงูุฑ ุงูุฒุงุด ุงูุช
   - ุฌุฑุงู ุฏุงุฏู ุฑูุงูโุชุฑ ุดุฏ
   - overlap ุจุดุชุฑ ุจู ูุฑุงุญู

3. **ุงูุชูุงู ุฏุงุฏู:**
   - ุงุฒ ุญุงูุช blocking ุจู async ุชุจุฏู ุดุฏ
   - GPU:0 ุจูุงูุงุตูู ฺฉุงุฑ ุจุนุฏ ุฑุง ุดุฑูุน ูโฺฉูุฏ
   - ุงุณุชูุงุฏู ุงุฒ hardware DMA

4. **Dataset:**
   - Prefetch ูุณุชูู ุจู GPU
   - ูพุฑุฏุงุฒุด ููุงุฒ ูุนุงู
   - ุชูุธู ุฎูุฏฺฉุงุฑ ูพุงุฑุงูุชุฑูุง

## ๐ ูุณุชูุฏุงุช

- **ุฑุงูููุง ฺฉุงูู:** [DUAL_GPU_BOTTLENECK_FIX.md](./DUAL_GPU_BOTTLENECK_FIX.md)
- **ุดุฑูุน ุณุฑุน:** [QUICK_START_DUAL_GPU_FIX.md](./QUICK_START_DUAL_GPU_FIX.md)
- **ุฑุงูููุง Memory Isolation:** [docs/MEMORY_ISOLATION_GUIDE.md](./docs/MEMORY_ISOLATION_GUIDE.md)

## ๐ ูุงูโูุง ุชุบุฑ ุงูุชู

### 1. `myxtts/training/memory_isolated_trainer.py`
**ุชุบุฑุงุช:**
- โ ูุนูุงุฑ async pipeline
- โ Triple buffering
- โ Async transfer functions
- โ Dataset optimization method
- โ Performance monitoring
- โ Auto-tuning

**ุฎุทูุท ฺฉุฏ:** ุญุฏูุฏ 150 ุฎุท ุงุถุงูู/ุชุบุฑ

### 2. `utilities/dual_gpu_bottleneck_profiler.py` (ุฌุฏุฏ)
**ูฺฺฏโูุง:**
- โ Profiling ฺฉุงูู pipeline
- โ ูุธุงุฑุช GPU realtime
- โ ุชุดุฎุต ุฎูุฏฺฉุงุฑ bottleneck
- โ ุชูุตูโูุง ุฎุงุต

**ุฎุทูุท ฺฉุฏ:** 850 ุฎุท ุฌุฏุฏ

### 3. `train_main.py`
**ุชุบุฑุงุช:**
- โ ููุงุด ุงุทูุงุนุงุช ุจุดุชุฑ
- โ ูุดุฏุงุฑูุง ุจุฑุง ุชูุธูุงุช ูุงููุงุณุจ
- โ ุชูุตูโูุง ุจูููโุณุงุฒ

## โจ ูุฒุงุง ุฑุงูฺฉุงุฑ

### ูุจู ุงุฒ ุจูููโุณุงุฒ:
- โ๏ธ GPU utilization ูพุงู (<70%)
- โ๏ธ ุฒูุงูโูุง ูุงูพุงุฏุงุฑ
- โ๏ธ GPUูุง ููุชุธุฑ ูโูุงูุฏูุฏ
- โ๏ธ OOM ุจุง batch ุจุฒุฑฺฏ

### ุจุนุฏ ุงุฒ ุจูููโุณุงุฒ:
- โ GPU utilization ุจุงูุง (>80%)
- โ ุฒูุงูโูุง ูพุงุฏุงุฑ
- โ ุงุณุชูุงุฏู ูุฏุงูู ุงุฒ GPUูุง
- โ ูพุดุชุจุงู batch ุจุฒุฑฺฏุชุฑ
- โ 2-3 ุจุฑุงุจุฑ ุณุฑุนุชุฑ

## ๐ ฺฺฉโูุณุช ูุจู ุงุฒ ุดุฑูุน

- [ ] Profiler ุฑุง ุงุฌุฑุง ฺฉุฑุฏุฏ
- [ ] ูฺ bottleneck ุจุฒุฑฺฏ ุดูุงุณุง ูุดุฏ
- [ ] Config ุจุฑ ุงุณุงุณ ุชูุตูโูุง profiler ุชูุธู ุดุฏ
- [ ] `nvidia-smi` ูุฑ ุฏู GPU ุฑุง ูุดุงู ูโุฏูุฏ
- [ ] ูุณุฑ dataset ุตุญุญ ุงุณุช
- [ ] Batch size ููุงุณุจ ุญุงูุธู GPU ุงุณุช
- [ ] `num_workers` ุงูุฒุงุด ุงูุชู (16-32 ุชูุตู ูโุดูุฏ)

## ๐ฏ ุงูุฏุงู ุนููฺฉุฑุฏ

### ุญุฏุงูู ูุงุจู ูุจูู:
- ุงุณุชูุงุฏู GPU:0: ุจุด ุงุฒ 40%
- ุงุณุชูุงุฏู GPU:1: ุจุด ุงุฒ 70%
- ุชุบุฑุงุช ุฒูุงู: ฺฉูุชุฑ ุงุฒ 40%
- ุจุฏูู ุฎุทุง OOM

### ุนููฺฉุฑุฏ ุฎูุจ:
- ุงุณุชูุงุฏู GPU:0: ุจุด ุงุฒ 50%
- ุงุณุชูุงุฏู GPU:1: ุจุด ุงุฒ 80%
- ุชุบุฑุงุช ุฒูุงู: ฺฉูุชุฑ ุงุฒ 30%
- ุขููุฒุด ูพุงุฏุงุฑ

### ุนููฺฉุฑุฏ ุนุงู:
- ุงุณุชูุงุฏู GPU:0: ุจุด ุงุฒ 60%
- ุงุณุชูุงุฏู GPU:1: ุจุด ุงุฒ 90%
- ุชุบุฑุงุช ุฒูุงู: ฺฉูุชุฑ ุงุฒ 20%
- 2-3 ุจุฑุงุจุฑ ุณุฑุนุชุฑ ุงุฒ single-GPU

## ๐ ุฏุฑุงูุช ฺฉูฺฉ

ุงฺฏุฑ ุจุนุฏ ุงุฒ ุงุนูุงู ุงู ุจูููโุณุงุฒโูุง ูููุฒ ูุดฺฉู ุฏุงุฑุฏ:

### 1. ุงุฌุฑุง ุชุณุช ฺฉุงูู:
```bash
# ุงุทูุงุนุงุช ุณุณุชู
nvidia-smi
nvidia-smi topo -m

# Profiler ฺฉุงูู
python utilities/dual_gpu_bottleneck_profiler.py \
  --batch-size 16 \
  --num-steps 100 \
  --data-gpu 0 \
  --model-gpu 1 \
  > profiler_output.txt 2>&1

# ุชุณุช ุขููุฒุด (100 step ุงูู)
python train_main.py \
  --model-size tiny \
  --batch-size 16 \
  --data-gpu 0 \
  --model-gpu 1 \
  --enable-memory-isolation \
  --train-data ./data \
  --max-steps 100 \
  > training_output.txt 2>&1
```

### 2. ุจู ุงุดุชุฑุงฺฉ ุจฺฏุฐุงุฑุฏ:
- `profiler_output.txt`
- `training_output.txt`
- ูุงู `config.yaml` ุดูุง
- ุฎุฑูุฌ `nvidia-smi`

---

## ๐ ุงุทูุงุนุงุช ูุณุฎู

- **ุชุงุฑุฎ:** 2025-10-10
- **ูุณุฎู:** 2.0
- **ูุถุนุช:** โ ุขูุงุฏู ุจุฑุง ุงุณุชูุงุฏู ู ุชุณุช

---

**ูููู ุจุงุดุฏ! ๐**

ุงู ุจูููโุณุงุฒโูุง ุจุงุฏ ุนููฺฉุฑุฏ dual-GPU pipeline ุฑุง ุจูโุทูุฑ ูุงุจูโุชูุฌู ุจูุจูุฏ ุจุฎุดูุฏ. ุงฺฏุฑ ุณุคุงู ุฏุงุฑุฏ ุง ุจู ฺฉูฺฉ ูุงุฒ ุฏุงุฑุฏุ ูุทูุงู ุจุง ุฌุฒุฆุงุช ฺฉุงูู (ูพุงูโูุง ุฎุทุงุ ุฎุฑูุฌ profilerุ ู...) ุณุคุงู ุจูพุฑุณุฏ.
