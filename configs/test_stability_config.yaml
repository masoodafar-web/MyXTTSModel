data:
  add_blank: true
  auto_tune_performance: true
  batch_size: 48
  cache_verification: true
  dataset_name: ljspeech
  dataset_path: ../dataset/dataset_train
  enable_memory_mapping: true
  enable_tensorrt: false
  enable_xla: true
  enhanced_gpu_prefetch: true
  eval_subset_fraction: 1.0
  language: en
  max_mel_frames: 1024
  max_text_tokens: 1024
  metadata_eval_file: ../dataset/dataset_eval/metadata_eval.csv
  metadata_train_file: ../dataset/dataset_train/metadata_train.csv
  mixed_precision: true
  normalize_audio: true
  num_workers: 16
  optimize_cpu_gpu_overlap: true
  persistent_workers: true
  pin_memory: true
  prefetch_buffer_size: 12
  prefetch_to_gpu: true
  preprocessing_mode: precompute
  sample_rate: 22050
  shuffle_buffer_multiplier: 20
  subset_seed: 42
  text_cleaners:
  - english_cleaners
  train_split: 0.9
  train_subset_fraction: 1.0
  trim_silence: true
  use_tf_native_loading: true
  val_split: 0.1
  wavs_eval_dir: ../dataset/dataset_train/wavs
  wavs_train_dir: ../dataset/dataset_train/wavs
model:
  audio_encoder_dim: 512
  audio_encoder_heads: 8
  audio_encoder_layers: 6
  decoder_dim: 1024
  decoder_heads: 16
  decoder_layers: 12
  enable_gradient_checkpointing: false
  hop_length: 256
  languages:
  - en
  - es
  - fr
  - de
  - it
  - pt
  - pl
  - tr
  - ru
  - nl
  - cs
  - ar
  - zh
  - ja
  - hu
  - ko
  max_attention_sequence_length: 512
  max_text_length: 500
  n_fft: 1024
  n_mels: 80
  sample_rate: 22050
  speaker_embedding_dim: 256
  text_encoder_dim: 512
  text_encoder_heads: 8
  text_encoder_layers: 6
  text_vocab_size: 256256
  tokenizer_model: facebook/nllb-200-distilled-600M
  tokenizer_type: nllb
  use_voice_conditioning: true
  win_length: 1024
training:
  beta1: 0.9
  beta2: 0.999
  checkpoint_dir: ./checkpoints
  cosine_restarts: false
  duration_loss_weight: 1.0
  early_stopping_min_delta: 0.0005
  early_stopping_patience: 25
  enable_memory_cleanup: true
  epochs: 100
  eps: 1.0e-08
  gradient_accumulation_steps: 1
  gradient_clip_norm: 1.0
  gradient_norm_threshold: 5.0
  huber_delta: 1.0
  kl_loss_weight: 1.0
  learning_rate: 0.0001
  log_step: 100
  loss_smoothing_factor: 0.1
  max_loss_spike_threshold: 2.0
  max_memory_fraction: 0.9
  mel_label_smoothing: 0.05
  mel_loss_weight: 35.0
  min_learning_rate: 1.0e-06
  multi_gpu: false
  optimizer: adamw
  save_step: 1000
  scheduler: noam
  scheduler_params: {}
  stop_label_smoothing: 0.1
  stop_token_positive_weight: 5.0
  use_adaptive_loss_weights: true
  use_huber_loss: true
  use_label_smoothing: true
  use_wandb: false
  use_warmup_cosine_schedule: true
  val_step: 500
  visible_gpus: null
  wandb_project: myxtts
  warmup_steps: 4000
  weight_decay: 1.0e-06
