# MyXTTS Hyperparameter Benchmark Configuration Examples

# Quick benchmark configuration (15-20 minutes)
quick_benchmark:
  model_sizes: ["tiny", "small"]
  optimization_levels: ["enhanced", "plateau_breaker"]
  learning_rates: [1.5e-5, 2e-5, 5e-5]
  batch_sizes: [4, 8, 16]
  gpu_stabilizer_options: [true, false]
  mel_loss_weights: [2.0, 2.5]
  kl_loss_weights: [1.2, 1.5]
  test_epochs: 5
  max_test_time: 180
  convergence_threshold: 0.01
  patience: 3

# Full comprehensive benchmark (2-4 hours)
full_benchmark:
  model_sizes: ["tiny", "small", "normal"]
  optimization_levels: ["basic", "enhanced", "experimental", "plateau_breaker"]
  learning_rates: [1e-5, 1.5e-5, 2e-5, 5e-5, 8e-5, 1e-4]
  batch_sizes: [4, 8, 16, 24, 32]
  gpu_stabilizer_options: [true, false]
  mel_loss_weights: [1.5, 2.0, 2.5, 3.0]
  kl_loss_weights: [1.0, 1.2, 1.5, 1.8]
  test_epochs: 15
  max_test_time: 600
  convergence_threshold: 0.01
  patience: 5

# Loss plateau specific benchmark
plateau_focused:
  model_sizes: ["tiny", "small"]
  optimization_levels: ["enhanced", "plateau_breaker"]
  learning_rates: [5e-6, 1e-5, 1.5e-5, 2e-5, 3e-5]
  batch_sizes: [8, 16, 24]
  gpu_stabilizer_options: [true]
  mel_loss_weights: [1.8, 2.0, 2.2, 2.5]
  kl_loss_weights: [1.0, 1.2, 1.4, 1.6]
  test_epochs: 20
  max_test_time: 900
  convergence_threshold: 0.005
  patience: 8

# GPU optimization focused benchmark
gpu_focused:
  model_sizes: ["small", "normal"]
  optimization_levels: ["enhanced"]
  learning_rates: [2e-5, 5e-5, 8e-5]
  batch_sizes: [8, 16, 32, 48, 64]
  gpu_stabilizer_options: [true, false]
  mel_loss_weights: [2.5]
  kl_loss_weights: [1.5]
  test_epochs: 10
  max_test_time: 300
  min_gpu_utilization: 60.0

# Memory optimization benchmark (for limited VRAM)
memory_constrained:
  model_sizes: ["tiny", "small"]
  optimization_levels: ["basic", "enhanced"]
  learning_rates: [1e-5, 2e-5, 5e-5]
  batch_sizes: [2, 4, 8]
  gpu_stabilizer_options: [false]  # Disable for memory constrained
  mel_loss_weights: [2.0, 2.5]
  kl_loss_weights: [1.2, 1.5]
  test_epochs: 8
  max_test_time: 240
  max_memory_usage: 0.7

# Voice cloning quality benchmark
voice_cloning_focused:
  model_sizes: ["normal"]
  optimization_levels: ["enhanced"]
  learning_rates: [2e-5, 5e-5]
  batch_sizes: [16, 24]
  gpu_stabilizer_options: [true]
  mel_loss_weights: [2.0, 2.5, 3.0]
  kl_loss_weights: [1.2, 1.5, 1.8]
  # Additional voice cloning specific parameters
  voice_similarity_loss_weights: [2.5, 3.0, 3.5]
  speaker_classification_weights: [1.0, 1.5, 2.0]
  test_epochs: 12
  max_test_time: 480